{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "import clip\n",
        "class CustomTextImageDataset(Dataset):\n",
        "    def __init__(self, df, img_folder, transform=None):\n",
        "        self.df = df\n",
        "        self.img_folder = img_folder\n",
        "        self.transform = transform\n",
        "        self.tokenizer = clip.tokenize\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_folder, self.df.iloc[idx, 1])\n",
        "        image = Image.open(img_name).convert(\"RGB\")\n",
        "        caption = self.df.iloc[idx, 2]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        caption_indices = self.tokenizer([caption], truncate=True)[0]\n",
        "\n",
        "        return image, caption_indices\n",
        "\n",
        "# Example usage\n",
        "df = pd.read_excel(r\"C:\\Users\\deepak\\Downloads\\archive\\images_info.xlsx\")\n",
        "img_folder = r\"C:\\Users\\deepak\\Downloads\\archive\\images\\images\"\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "dataset = CustomTextImageDataset(df, img_folder, transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\deepa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
            "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/1500], Step [1/65], Loss: 0.0929\n",
            "Epoch [1/1500], Loss: 0.1014\n",
            "Epoch [2/1500], Step [1/65], Loss: 0.0953\n",
            "Epoch [2/1500], Loss: 0.0946\n",
            "Epoch [3/1500], Step [1/65], Loss: 0.0773\n",
            "Epoch [3/1500], Loss: 0.0907\n",
            "Epoch [4/1500], Step [1/65], Loss: 0.0965\n",
            "Epoch [4/1500], Loss: 0.0875\n",
            "Epoch [5/1500], Step [1/65], Loss: 0.0904\n",
            "Epoch [5/1500], Loss: 0.0851\n",
            "Epoch [6/1500], Step [1/65], Loss: 0.0829\n",
            "Epoch [6/1500], Loss: 0.0830\n",
            "Epoch [7/1500], Step [1/65], Loss: 0.0721\n",
            "Epoch [7/1500], Loss: 0.0809\n",
            "Epoch [8/1500], Step [1/65], Loss: 0.0840\n",
            "Epoch [8/1500], Loss: 0.0796\n",
            "Epoch [9/1500], Step [1/65], Loss: 0.0814\n",
            "Epoch [9/1500], Loss: 0.0787\n",
            "Epoch [10/1500], Step [1/65], Loss: 0.0700\n",
            "Epoch [10/1500], Loss: 0.0769\n",
            "Epoch [11/1500], Step [1/65], Loss: 0.0628\n",
            "Epoch [11/1500], Loss: 0.0761\n",
            "Epoch [12/1500], Step [1/65], Loss: 0.0737\n",
            "Epoch [12/1500], Loss: 0.0749\n",
            "Epoch [13/1500], Step [1/65], Loss: 0.0643\n",
            "Epoch [13/1500], Loss: 0.0738\n",
            "Epoch [14/1500], Step [1/65], Loss: 0.0670\n",
            "Epoch [14/1500], Loss: 0.0724\n",
            "Epoch [15/1500], Step [1/65], Loss: 0.0647\n",
            "Epoch [15/1500], Loss: 0.0711\n",
            "Epoch [16/1500], Step [1/65], Loss: 0.0613\n",
            "Epoch [16/1500], Loss: 0.0701\n",
            "Epoch [17/1500], Step [1/65], Loss: 0.0692\n",
            "Epoch [17/1500], Loss: 0.0686\n",
            "Epoch [18/1500], Step [1/65], Loss: 0.0701\n",
            "Epoch [18/1500], Loss: 0.0674\n",
            "Epoch [19/1500], Step [1/65], Loss: 0.0693\n",
            "Epoch [19/1500], Loss: 0.0660\n",
            "Epoch [20/1500], Step [1/65], Loss: 0.0653\n",
            "Epoch [20/1500], Loss: 0.0650\n",
            "Epoch [21/1500], Step [1/65], Loss: 0.0651\n",
            "Epoch [21/1500], Loss: 0.0645\n",
            "Epoch [22/1500], Step [1/65], Loss: 0.0530\n",
            "Epoch [22/1500], Loss: 0.0629\n",
            "Epoch [23/1500], Step [1/65], Loss: 0.0627\n",
            "Epoch [23/1500], Loss: 0.0619\n",
            "Epoch [24/1500], Step [1/65], Loss: 0.0649\n",
            "Epoch [24/1500], Loss: 0.0610\n",
            "Epoch [25/1500], Step [1/65], Loss: 0.0579\n",
            "Epoch [25/1500], Loss: 0.0598\n",
            "Epoch [26/1500], Step [1/65], Loss: 0.0650\n",
            "Epoch [26/1500], Loss: 0.0586\n",
            "Epoch [27/1500], Step [1/65], Loss: 0.0500\n",
            "Epoch [27/1500], Loss: 0.0574\n",
            "Epoch [28/1500], Step [1/65], Loss: 0.0536\n",
            "Epoch [28/1500], Loss: 0.0561\n",
            "Epoch [29/1500], Step [1/65], Loss: 0.0561\n",
            "Epoch [29/1500], Loss: 0.0550\n",
            "Epoch [30/1500], Step [1/65], Loss: 0.0520\n",
            "Epoch [30/1500], Loss: 0.0538\n",
            "Epoch [31/1500], Step [1/65], Loss: 0.0514\n",
            "Epoch [31/1500], Loss: 0.0523\n",
            "Epoch [32/1500], Step [1/65], Loss: 0.0469\n",
            "Epoch [32/1500], Loss: 0.0508\n",
            "Epoch [33/1500], Step [1/65], Loss: 0.0528\n",
            "Epoch [33/1500], Loss: 0.0497\n",
            "Epoch [34/1500], Step [1/65], Loss: 0.0484\n",
            "Epoch [34/1500], Loss: 0.0480\n",
            "Epoch [35/1500], Step [1/65], Loss: 0.0426\n",
            "Epoch [35/1500], Loss: 0.0468\n",
            "Epoch [36/1500], Step [1/65], Loss: 0.0429\n",
            "Epoch [36/1500], Loss: 0.0454\n",
            "Epoch [37/1500], Step [1/65], Loss: 0.0445\n",
            "Epoch [37/1500], Loss: 0.0443\n",
            "Epoch [38/1500], Step [1/65], Loss: 0.0355\n",
            "Epoch [38/1500], Loss: 0.0431\n",
            "Epoch [39/1500], Step [1/65], Loss: 0.0435\n",
            "Epoch [39/1500], Loss: 0.0423\n",
            "Epoch [40/1500], Step [1/65], Loss: 0.0362\n",
            "Epoch [40/1500], Loss: 0.0410\n",
            "Epoch [41/1500], Step [1/65], Loss: 0.0407\n",
            "Epoch [41/1500], Loss: 0.0399\n",
            "Epoch [42/1500], Step [1/65], Loss: 0.0342\n",
            "Epoch [42/1500], Loss: 0.0391\n",
            "Epoch [43/1500], Step [1/65], Loss: 0.0348\n",
            "Epoch [43/1500], Loss: 0.0381\n",
            "Epoch [44/1500], Step [1/65], Loss: 0.0355\n",
            "Epoch [44/1500], Loss: 0.0370\n",
            "Epoch [45/1500], Step [1/65], Loss: 0.0365\n",
            "Epoch [45/1500], Loss: 0.0363\n",
            "Epoch [46/1500], Step [1/65], Loss: 0.0326\n",
            "Epoch [46/1500], Loss: 0.0355\n",
            "Epoch [47/1500], Step [1/65], Loss: 0.0329\n",
            "Epoch [47/1500], Loss: 0.0347\n",
            "Epoch [48/1500], Step [1/65], Loss: 0.0329\n",
            "Epoch [48/1500], Loss: 0.0341\n",
            "Epoch [49/1500], Step [1/65], Loss: 0.0347\n",
            "Epoch [49/1500], Loss: 0.0334\n",
            "Epoch [50/1500], Step [1/65], Loss: 0.0322\n",
            "Epoch [50/1500], Loss: 0.0327\n",
            "Epoch [51/1500], Step [1/65], Loss: 0.0341\n",
            "Epoch [51/1500], Loss: 0.0321\n",
            "Epoch [52/1500], Step [1/65], Loss: 0.0299\n",
            "Epoch [52/1500], Loss: 0.0315\n",
            "Epoch [53/1500], Step [1/65], Loss: 0.0300\n",
            "Epoch [53/1500], Loss: 0.0307\n",
            "Epoch [54/1500], Step [1/65], Loss: 0.0301\n",
            "Epoch [54/1500], Loss: 0.0305\n",
            "Epoch [55/1500], Step [1/65], Loss: 0.0288\n",
            "Epoch [55/1500], Loss: 0.0299\n",
            "Epoch [56/1500], Step [1/65], Loss: 0.0298\n",
            "Epoch [56/1500], Loss: 0.0293\n",
            "Epoch [57/1500], Step [1/65], Loss: 0.0241\n",
            "Epoch [57/1500], Loss: 0.0288\n",
            "Epoch [58/1500], Step [1/65], Loss: 0.0315\n",
            "Epoch [58/1500], Loss: 0.0280\n",
            "Epoch [59/1500], Step [1/65], Loss: 0.0259\n",
            "Epoch [59/1500], Loss: 0.0275\n",
            "Epoch [60/1500], Step [1/65], Loss: 0.0292\n",
            "Epoch [60/1500], Loss: 0.0269\n",
            "Epoch [61/1500], Step [1/65], Loss: 0.0246\n",
            "Epoch [61/1500], Loss: 0.0267\n",
            "Epoch [62/1500], Step [1/65], Loss: 0.0283\n",
            "Epoch [62/1500], Loss: 0.0266\n",
            "Epoch [63/1500], Step [1/65], Loss: 0.0264\n",
            "Epoch [63/1500], Loss: 0.0259\n",
            "Epoch [64/1500], Step [1/65], Loss: 0.0245\n",
            "Epoch [64/1500], Loss: 0.0254\n",
            "Epoch [65/1500], Step [1/65], Loss: 0.0211\n",
            "Epoch [65/1500], Loss: 0.0250\n",
            "Epoch [66/1500], Step [1/65], Loss: 0.0209\n",
            "Epoch [66/1500], Loss: 0.0249\n",
            "Epoch [67/1500], Step [1/65], Loss: 0.0242\n",
            "Epoch [67/1500], Loss: 0.0244\n",
            "Epoch [68/1500], Step [1/65], Loss: 0.0263\n",
            "Epoch [68/1500], Loss: 0.0240\n",
            "Epoch [69/1500], Step [1/65], Loss: 0.0279\n",
            "Epoch [69/1500], Loss: 0.0239\n",
            "Epoch [70/1500], Step [1/65], Loss: 0.0263\n",
            "Epoch [70/1500], Loss: 0.0236\n",
            "Epoch [71/1500], Step [1/65], Loss: 0.0231\n",
            "Epoch [71/1500], Loss: 0.0234\n",
            "Epoch [72/1500], Step [1/65], Loss: 0.0248\n",
            "Epoch [72/1500], Loss: 0.0231\n",
            "Epoch [73/1500], Step [1/65], Loss: 0.0213\n",
            "Epoch [73/1500], Loss: 0.0224\n",
            "Epoch [74/1500], Step [1/65], Loss: 0.0220\n",
            "Epoch [74/1500], Loss: 0.0222\n",
            "Epoch [75/1500], Step [1/65], Loss: 0.0177\n",
            "Epoch [75/1500], Loss: 0.0218\n",
            "Epoch [76/1500], Step [1/65], Loss: 0.0207\n",
            "Epoch [76/1500], Loss: 0.0216\n",
            "Epoch [77/1500], Step [1/65], Loss: 0.0254\n",
            "Epoch [77/1500], Loss: 0.0216\n",
            "Epoch [78/1500], Step [1/65], Loss: 0.0211\n",
            "Epoch [78/1500], Loss: 0.0215\n",
            "Epoch [79/1500], Step [1/65], Loss: 0.0245\n",
            "Epoch [79/1500], Loss: 0.0212\n",
            "Epoch [80/1500], Step [1/65], Loss: 0.0188\n",
            "Epoch [80/1500], Loss: 0.0208\n",
            "Epoch [81/1500], Step [1/65], Loss: 0.0221\n",
            "Epoch [81/1500], Loss: 0.0206\n",
            "Epoch [82/1500], Step [1/65], Loss: 0.0177\n",
            "Epoch [82/1500], Loss: 0.0203\n",
            "Epoch [83/1500], Step [1/65], Loss: 0.0190\n",
            "Epoch [83/1500], Loss: 0.0201\n",
            "Epoch [84/1500], Step [1/65], Loss: 0.0174\n",
            "Epoch [84/1500], Loss: 0.0199\n",
            "Epoch [85/1500], Step [1/65], Loss: 0.0207\n",
            "Epoch [85/1500], Loss: 0.0199\n",
            "Epoch [86/1500], Step [1/65], Loss: 0.0208\n",
            "Epoch [86/1500], Loss: 0.0201\n",
            "Epoch [87/1500], Step [1/65], Loss: 0.0186\n",
            "Epoch [87/1500], Loss: 0.0199\n",
            "Epoch [88/1500], Step [1/65], Loss: 0.0178\n",
            "Epoch [88/1500], Loss: 0.0197\n",
            "Epoch [89/1500], Step [1/65], Loss: 0.0181\n",
            "Epoch [89/1500], Loss: 0.0194\n",
            "Epoch [90/1500], Step [1/65], Loss: 0.0194\n",
            "Epoch [90/1500], Loss: 0.0192\n",
            "Epoch [91/1500], Step [1/65], Loss: 0.0180\n",
            "Epoch [91/1500], Loss: 0.0188\n",
            "Epoch [92/1500], Step [1/65], Loss: 0.0144\n",
            "Epoch [92/1500], Loss: 0.0187\n",
            "Epoch [93/1500], Step [1/65], Loss: 0.0175\n",
            "Epoch [93/1500], Loss: 0.0186\n",
            "Epoch [94/1500], Step [1/65], Loss: 0.0152\n",
            "Epoch [94/1500], Loss: 0.0183\n",
            "Epoch [95/1500], Step [1/65], Loss: 0.0201\n",
            "Epoch [95/1500], Loss: 0.0182\n",
            "Epoch [96/1500], Step [1/65], Loss: 0.0160\n",
            "Epoch [96/1500], Loss: 0.0183\n",
            "Epoch [97/1500], Step [1/65], Loss: 0.0177\n",
            "Epoch [97/1500], Loss: 0.0180\n",
            "Epoch [98/1500], Step [1/65], Loss: 0.0192\n",
            "Epoch [98/1500], Loss: 0.0180\n",
            "Epoch [99/1500], Step [1/65], Loss: 0.0165\n",
            "Epoch [99/1500], Loss: 0.0178\n",
            "Epoch [100/1500], Step [1/65], Loss: 0.0180\n",
            "Epoch [100/1500], Loss: 0.0178\n",
            "Epoch [101/1500], Step [1/65], Loss: 0.0196\n",
            "Epoch [101/1500], Loss: 0.0176\n",
            "Epoch [102/1500], Step [1/65], Loss: 0.0175\n",
            "Epoch [102/1500], Loss: 0.0174\n",
            "Epoch [103/1500], Step [1/65], Loss: 0.0167\n",
            "Epoch [103/1500], Loss: 0.0174\n",
            "Epoch [104/1500], Step [1/65], Loss: 0.0221\n",
            "Epoch [104/1500], Loss: 0.0172\n",
            "Epoch [105/1500], Step [1/65], Loss: 0.0187\n",
            "Epoch [105/1500], Loss: 0.0173\n",
            "Epoch [106/1500], Step [1/65], Loss: 0.0161\n",
            "Epoch [106/1500], Loss: 0.0172\n",
            "Epoch [107/1500], Step [1/65], Loss: 0.0158\n",
            "Epoch [107/1500], Loss: 0.0169\n",
            "Epoch [108/1500], Step [1/65], Loss: 0.0172\n",
            "Epoch [108/1500], Loss: 0.0167\n",
            "Epoch [109/1500], Step [1/65], Loss: 0.0159\n",
            "Epoch [109/1500], Loss: 0.0165\n",
            "Epoch [110/1500], Step [1/65], Loss: 0.0165\n",
            "Epoch [110/1500], Loss: 0.0164\n",
            "Epoch [111/1500], Step [1/65], Loss: 0.0144\n",
            "Epoch [111/1500], Loss: 0.0162\n",
            "Epoch [112/1500], Step [1/65], Loss: 0.0164\n",
            "Epoch [112/1500], Loss: 0.0161\n",
            "Epoch [113/1500], Step [1/65], Loss: 0.0164\n",
            "Epoch [113/1500], Loss: 0.0162\n",
            "Epoch [114/1500], Step [1/65], Loss: 0.0170\n",
            "Epoch [114/1500], Loss: 0.0162\n",
            "Epoch [115/1500], Step [1/65], Loss: 0.0147\n",
            "Epoch [115/1500], Loss: 0.0162\n",
            "Epoch [116/1500], Step [1/65], Loss: 0.0154\n",
            "Epoch [116/1500], Loss: 0.0161\n",
            "Epoch [117/1500], Step [1/65], Loss: 0.0164\n",
            "Epoch [117/1500], Loss: 0.0159\n",
            "Epoch [118/1500], Step [1/65], Loss: 0.0177\n",
            "Epoch [118/1500], Loss: 0.0160\n",
            "Epoch [119/1500], Step [1/65], Loss: 0.0173\n",
            "Epoch [119/1500], Loss: 0.0155\n",
            "Epoch [120/1500], Step [1/65], Loss: 0.0159\n",
            "Epoch [120/1500], Loss: 0.0152\n",
            "Epoch [121/1500], Step [1/65], Loss: 0.0129\n",
            "Epoch [121/1500], Loss: 0.0153\n",
            "Epoch [122/1500], Step [1/65], Loss: 0.0166\n",
            "Epoch [122/1500], Loss: 0.0155\n",
            "Epoch [123/1500], Step [1/65], Loss: 0.0143\n",
            "Epoch [123/1500], Loss: 0.0151\n",
            "Epoch [124/1500], Step [1/65], Loss: 0.0129\n",
            "Epoch [124/1500], Loss: 0.0148\n",
            "Epoch [125/1500], Step [1/65], Loss: 0.0136\n",
            "Epoch [125/1500], Loss: 0.0147\n",
            "Epoch [126/1500], Step [1/65], Loss: 0.0168\n",
            "Epoch [126/1500], Loss: 0.0144\n",
            "Epoch [127/1500], Step [1/65], Loss: 0.0134\n",
            "Epoch [127/1500], Loss: 0.0143\n",
            "Epoch [128/1500], Step [1/65], Loss: 0.0170\n",
            "Epoch [128/1500], Loss: 0.0144\n",
            "Epoch [129/1500], Step [1/65], Loss: 0.0143\n",
            "Epoch [129/1500], Loss: 0.0143\n",
            "Epoch [130/1500], Step [1/65], Loss: 0.0155\n",
            "Epoch [130/1500], Loss: 0.0143\n",
            "Epoch [131/1500], Step [1/65], Loss: 0.0165\n",
            "Epoch [131/1500], Loss: 0.0144\n",
            "Epoch [132/1500], Step [1/65], Loss: 0.0160\n",
            "Epoch [132/1500], Loss: 0.0144\n",
            "Epoch [133/1500], Step [1/65], Loss: 0.0153\n",
            "Epoch [133/1500], Loss: 0.0141\n",
            "Epoch [134/1500], Step [1/65], Loss: 0.0108\n",
            "Epoch [134/1500], Loss: 0.0138\n",
            "Epoch [135/1500], Step [1/65], Loss: 0.0134\n",
            "Epoch [135/1500], Loss: 0.0135\n",
            "Epoch [136/1500], Step [1/65], Loss: 0.0149\n",
            "Epoch [136/1500], Loss: 0.0135\n",
            "Epoch [137/1500], Step [1/65], Loss: 0.0134\n",
            "Epoch [137/1500], Loss: 0.0135\n",
            "Epoch [138/1500], Step [1/65], Loss: 0.0148\n",
            "Epoch [138/1500], Loss: 0.0135\n",
            "Epoch [139/1500], Step [1/65], Loss: 0.0135\n",
            "Epoch [139/1500], Loss: 0.0136\n",
            "Epoch [140/1500], Step [1/65], Loss: 0.0133\n",
            "Epoch [140/1500], Loss: 0.0135\n",
            "Epoch [141/1500], Step [1/65], Loss: 0.0150\n",
            "Epoch [141/1500], Loss: 0.0132\n",
            "Epoch [142/1500], Step [1/65], Loss: 0.0113\n",
            "Epoch [142/1500], Loss: 0.0129\n",
            "Epoch [143/1500], Step [1/65], Loss: 0.0123\n",
            "Epoch [143/1500], Loss: 0.0128\n",
            "Epoch [144/1500], Step [1/65], Loss: 0.0134\n",
            "Epoch [144/1500], Loss: 0.0127\n",
            "Epoch [145/1500], Step [1/65], Loss: 0.0109\n",
            "Epoch [145/1500], Loss: 0.0126\n",
            "Epoch [146/1500], Step [1/65], Loss: 0.0121\n",
            "Epoch [146/1500], Loss: 0.0126\n",
            "Epoch [147/1500], Step [1/65], Loss: 0.0125\n",
            "Epoch [147/1500], Loss: 0.0126\n",
            "Epoch [148/1500], Step [1/65], Loss: 0.0109\n",
            "Epoch [148/1500], Loss: 0.0125\n",
            "Epoch [149/1500], Step [1/65], Loss: 0.0140\n",
            "Epoch [149/1500], Loss: 0.0125\n",
            "Epoch [150/1500], Step [1/65], Loss: 0.0117\n",
            "Epoch [150/1500], Loss: 0.0126\n",
            "Epoch [151/1500], Step [1/65], Loss: 0.0116\n",
            "Epoch [151/1500], Loss: 0.0123\n",
            "Epoch [152/1500], Step [1/65], Loss: 0.0115\n",
            "Epoch [152/1500], Loss: 0.0124\n",
            "Epoch [153/1500], Step [1/65], Loss: 0.0098\n",
            "Epoch [153/1500], Loss: 0.0123\n",
            "Epoch [154/1500], Step [1/65], Loss: 0.0112\n",
            "Epoch [154/1500], Loss: 0.0123\n",
            "Epoch [155/1500], Step [1/65], Loss: 0.0114\n",
            "Epoch [155/1500], Loss: 0.0120\n",
            "Epoch [156/1500], Step [1/65], Loss: 0.0114\n",
            "Epoch [156/1500], Loss: 0.0119\n",
            "Epoch [157/1500], Step [1/65], Loss: 0.0100\n",
            "Epoch [157/1500], Loss: 0.0117\n",
            "Epoch [158/1500], Step [1/65], Loss: 0.0094\n",
            "Epoch [158/1500], Loss: 0.0118\n",
            "Epoch [159/1500], Step [1/65], Loss: 0.0116\n",
            "Epoch [159/1500], Loss: 0.0116\n",
            "Epoch [160/1500], Step [1/65], Loss: 0.0109\n",
            "Epoch [160/1500], Loss: 0.0115\n",
            "Epoch [161/1500], Step [1/65], Loss: 0.0139\n",
            "Epoch [161/1500], Loss: 0.0116\n",
            "Epoch [162/1500], Step [1/65], Loss: 0.0132\n",
            "Epoch [162/1500], Loss: 0.0115\n",
            "Epoch [163/1500], Step [1/65], Loss: 0.0106\n",
            "Epoch [163/1500], Loss: 0.0119\n",
            "Epoch [164/1500], Step [1/65], Loss: 0.0096\n",
            "Epoch [164/1500], Loss: 0.0116\n",
            "Epoch [165/1500], Step [1/65], Loss: 0.0094\n",
            "Epoch [165/1500], Loss: 0.0115\n",
            "Epoch [166/1500], Step [1/65], Loss: 0.0108\n",
            "Epoch [166/1500], Loss: 0.0114\n",
            "Epoch [167/1500], Step [1/65], Loss: 0.0101\n",
            "Epoch [167/1500], Loss: 0.0113\n",
            "Epoch [168/1500], Step [1/65], Loss: 0.0127\n",
            "Epoch [168/1500], Loss: 0.0112\n",
            "Epoch [169/1500], Step [1/65], Loss: 0.0095\n",
            "Epoch [169/1500], Loss: 0.0111\n",
            "Epoch [170/1500], Step [1/65], Loss: 0.0105\n",
            "Epoch [170/1500], Loss: 0.0112\n",
            "Epoch [171/1500], Step [1/65], Loss: 0.0106\n",
            "Epoch [171/1500], Loss: 0.0110\n",
            "Epoch [172/1500], Step [1/65], Loss: 0.0109\n",
            "Epoch [172/1500], Loss: 0.0109\n",
            "Epoch [173/1500], Step [1/65], Loss: 0.0101\n",
            "Epoch [173/1500], Loss: 0.0108\n",
            "Epoch [174/1500], Step [1/65], Loss: 0.0106\n",
            "Epoch [174/1500], Loss: 0.0108\n",
            "Epoch [175/1500], Step [1/65], Loss: 0.0092\n",
            "Epoch [175/1500], Loss: 0.0108\n",
            "Epoch [176/1500], Step [1/65], Loss: 0.0101\n",
            "Epoch [176/1500], Loss: 0.0107\n",
            "Epoch [177/1500], Step [1/65], Loss: 0.0120\n",
            "Epoch [177/1500], Loss: 0.0107\n",
            "Epoch [178/1500], Step [1/65], Loss: 0.0113\n",
            "Epoch [178/1500], Loss: 0.0108\n",
            "Epoch [179/1500], Step [1/65], Loss: 0.0092\n",
            "Epoch [179/1500], Loss: 0.0108\n",
            "Epoch [180/1500], Step [1/65], Loss: 0.0119\n",
            "Epoch [180/1500], Loss: 0.0109\n",
            "Epoch [181/1500], Step [1/65], Loss: 0.0098\n",
            "Epoch [181/1500], Loss: 0.0108\n",
            "Epoch [182/1500], Step [1/65], Loss: 0.0103\n",
            "Epoch [182/1500], Loss: 0.0107\n",
            "Epoch [183/1500], Step [1/65], Loss: 0.0103\n",
            "Epoch [183/1500], Loss: 0.0105\n",
            "Epoch [184/1500], Step [1/65], Loss: 0.0106\n",
            "Epoch [184/1500], Loss: 0.0106\n",
            "Epoch [185/1500], Step [1/65], Loss: 0.0099\n",
            "Epoch [185/1500], Loss: 0.0104\n",
            "Epoch [186/1500], Step [1/65], Loss: 0.0103\n",
            "Epoch [186/1500], Loss: 0.0104\n",
            "Epoch [187/1500], Step [1/65], Loss: 0.0090\n",
            "Epoch [187/1500], Loss: 0.0103\n",
            "Epoch [188/1500], Step [1/65], Loss: 0.0105\n",
            "Epoch [188/1500], Loss: 0.0102\n",
            "Epoch [189/1500], Step [1/65], Loss: 0.0096\n",
            "Epoch [189/1500], Loss: 0.0101\n",
            "Epoch [190/1500], Step [1/65], Loss: 0.0120\n",
            "Epoch [190/1500], Loss: 0.0101\n",
            "Epoch [191/1500], Step [1/65], Loss: 0.0115\n",
            "Epoch [191/1500], Loss: 0.0101\n",
            "Epoch [192/1500], Step [1/65], Loss: 0.0089\n",
            "Epoch [192/1500], Loss: 0.0101\n",
            "Epoch [193/1500], Step [1/65], Loss: 0.0088\n",
            "Epoch [193/1500], Loss: 0.0101\n",
            "Epoch [194/1500], Step [1/65], Loss: 0.0094\n",
            "Epoch [194/1500], Loss: 0.0102\n",
            "Epoch [195/1500], Step [1/65], Loss: 0.0093\n",
            "Epoch [195/1500], Loss: 0.0102\n",
            "Epoch [196/1500], Step [1/65], Loss: 0.0103\n",
            "Epoch [196/1500], Loss: 0.0101\n",
            "Epoch [197/1500], Step [1/65], Loss: 0.0098\n",
            "Epoch [197/1500], Loss: 0.0101\n",
            "Epoch [198/1500], Step [1/65], Loss: 0.0098\n",
            "Epoch [198/1500], Loss: 0.0100\n",
            "Epoch [199/1500], Step [1/65], Loss: 0.0104\n",
            "Epoch [199/1500], Loss: 0.0099\n",
            "Epoch [200/1500], Step [1/65], Loss: 0.0098\n",
            "Epoch [200/1500], Loss: 0.0101\n",
            "Epoch [201/1500], Step [1/65], Loss: 0.0087\n",
            "Epoch [201/1500], Loss: 0.0098\n",
            "Epoch [202/1500], Step [1/65], Loss: 0.0093\n",
            "Epoch [202/1500], Loss: 0.0098\n",
            "Epoch [203/1500], Step [1/65], Loss: 0.0104\n",
            "Epoch [203/1500], Loss: 0.0098\n",
            "Epoch [204/1500], Step [1/65], Loss: 0.0083\n",
            "Epoch [204/1500], Loss: 0.0097\n",
            "Epoch [205/1500], Step [1/65], Loss: 0.0087\n",
            "Epoch [205/1500], Loss: 0.0096\n",
            "Epoch [206/1500], Step [1/65], Loss: 0.0090\n",
            "Epoch [206/1500], Loss: 0.0097\n",
            "Epoch [207/1500], Step [1/65], Loss: 0.0092\n",
            "Epoch [207/1500], Loss: 0.0100\n",
            "Epoch [208/1500], Step [1/65], Loss: 0.0105\n",
            "Epoch [208/1500], Loss: 0.0096\n",
            "Epoch [209/1500], Step [1/65], Loss: 0.0077\n",
            "Epoch [209/1500], Loss: 0.0095\n",
            "Epoch [210/1500], Step [1/65], Loss: 0.0096\n",
            "Epoch [210/1500], Loss: 0.0094\n",
            "Epoch [211/1500], Step [1/65], Loss: 0.0090\n",
            "Epoch [211/1500], Loss: 0.0095\n",
            "Epoch [212/1500], Step [1/65], Loss: 0.0086\n",
            "Epoch [212/1500], Loss: 0.0096\n",
            "Epoch [213/1500], Step [1/65], Loss: 0.0082\n",
            "Epoch [213/1500], Loss: 0.0097\n",
            "Epoch [214/1500], Step [1/65], Loss: 0.0114\n",
            "Epoch [214/1500], Loss: 0.0095\n",
            "Epoch [215/1500], Step [1/65], Loss: 0.0093\n",
            "Epoch [215/1500], Loss: 0.0094\n",
            "Epoch [216/1500], Step [1/65], Loss: 0.0103\n",
            "Epoch [216/1500], Loss: 0.0096\n",
            "Epoch [217/1500], Step [1/65], Loss: 0.0094\n",
            "Epoch [217/1500], Loss: 0.0096\n",
            "Epoch [218/1500], Step [1/65], Loss: 0.0088\n",
            "Epoch [218/1500], Loss: 0.0096\n",
            "Epoch [219/1500], Step [1/65], Loss: 0.0091\n",
            "Epoch [219/1500], Loss: 0.0093\n",
            "Epoch [220/1500], Step [1/65], Loss: 0.0082\n",
            "Epoch [220/1500], Loss: 0.0093\n",
            "Epoch [221/1500], Step [1/65], Loss: 0.0081\n",
            "Epoch [221/1500], Loss: 0.0093\n",
            "Epoch [222/1500], Step [1/65], Loss: 0.0102\n",
            "Epoch [222/1500], Loss: 0.0092\n",
            "Epoch [223/1500], Step [1/65], Loss: 0.0090\n",
            "Epoch [223/1500], Loss: 0.0091\n",
            "Epoch [224/1500], Step [1/65], Loss: 0.0083\n",
            "Epoch [224/1500], Loss: 0.0092\n",
            "Epoch [225/1500], Step [1/65], Loss: 0.0075\n",
            "Epoch [225/1500], Loss: 0.0091\n",
            "Epoch [226/1500], Step [1/65], Loss: 0.0069\n",
            "Epoch [226/1500], Loss: 0.0090\n",
            "Epoch [227/1500], Step [1/65], Loss: 0.0108\n",
            "Epoch [227/1500], Loss: 0.0088\n",
            "Epoch [228/1500], Step [1/65], Loss: 0.0087\n",
            "Epoch [228/1500], Loss: 0.0088\n",
            "Epoch [229/1500], Step [1/65], Loss: 0.0082\n",
            "Epoch [229/1500], Loss: 0.0087\n",
            "Epoch [230/1500], Step [1/65], Loss: 0.0085\n",
            "Epoch [230/1500], Loss: 0.0088\n",
            "Epoch [231/1500], Step [1/65], Loss: 0.0083\n",
            "Epoch [231/1500], Loss: 0.0089\n",
            "Epoch [232/1500], Step [1/65], Loss: 0.0085\n",
            "Epoch [232/1500], Loss: 0.0090\n",
            "Epoch [233/1500], Step [1/65], Loss: 0.0086\n",
            "Epoch [233/1500], Loss: 0.0089\n",
            "Epoch [234/1500], Step [1/65], Loss: 0.0071\n",
            "Epoch [234/1500], Loss: 0.0090\n",
            "Epoch [235/1500], Step [1/65], Loss: 0.0084\n",
            "Epoch [235/1500], Loss: 0.0090\n",
            "Epoch [236/1500], Step [1/65], Loss: 0.0084\n",
            "Epoch [236/1500], Loss: 0.0088\n",
            "Epoch [237/1500], Step [1/65], Loss: 0.0077\n",
            "Epoch [237/1500], Loss: 0.0089\n",
            "Epoch [238/1500], Step [1/65], Loss: 0.0070\n",
            "Epoch [238/1500], Loss: 0.0089\n",
            "Epoch [239/1500], Step [1/65], Loss: 0.0110\n",
            "Epoch [239/1500], Loss: 0.0090\n",
            "Epoch [240/1500], Step [1/65], Loss: 0.0100\n",
            "Epoch [240/1500], Loss: 0.0092\n",
            "Epoch [241/1500], Step [1/65], Loss: 0.0086\n",
            "Epoch [241/1500], Loss: 0.0091\n",
            "Epoch [242/1500], Step [1/65], Loss: 0.0084\n",
            "Epoch [242/1500], Loss: 0.0091\n",
            "Epoch [243/1500], Step [1/65], Loss: 0.0089\n",
            "Epoch [243/1500], Loss: 0.0089\n",
            "Epoch [244/1500], Step [1/65], Loss: 0.0084\n",
            "Epoch [244/1500], Loss: 0.0086\n",
            "Epoch [245/1500], Step [1/65], Loss: 0.0090\n",
            "Epoch [245/1500], Loss: 0.0087\n",
            "Epoch [246/1500], Step [1/65], Loss: 0.0082\n",
            "Epoch [246/1500], Loss: 0.0089\n",
            "Epoch [247/1500], Step [1/65], Loss: 0.0084\n",
            "Epoch [247/1500], Loss: 0.0087\n",
            "Epoch [248/1500], Step [1/65], Loss: 0.0076\n",
            "Epoch [248/1500], Loss: 0.0084\n",
            "Epoch [249/1500], Step [1/65], Loss: 0.0081\n",
            "Epoch [249/1500], Loss: 0.0084\n",
            "Epoch [250/1500], Step [1/65], Loss: 0.0073\n",
            "Epoch [250/1500], Loss: 0.0084\n",
            "Epoch [251/1500], Step [1/65], Loss: 0.0077\n",
            "Epoch [251/1500], Loss: 0.0085\n",
            "Epoch [252/1500], Step [1/65], Loss: 0.0069\n",
            "Epoch [252/1500], Loss: 0.0084\n",
            "Epoch [253/1500], Step [1/65], Loss: 0.0097\n",
            "Epoch [253/1500], Loss: 0.0085\n",
            "Epoch [254/1500], Step [1/65], Loss: 0.0081\n",
            "Epoch [254/1500], Loss: 0.0084\n",
            "Epoch [255/1500], Step [1/65], Loss: 0.0097\n",
            "Epoch [255/1500], Loss: 0.0085\n",
            "Epoch [256/1500], Step [1/65], Loss: 0.0077\n",
            "Epoch [256/1500], Loss: 0.0084\n",
            "Epoch [257/1500], Step [1/65], Loss: 0.0065\n",
            "Epoch [257/1500], Loss: 0.0085\n",
            "Epoch [258/1500], Step [1/65], Loss: 0.0091\n",
            "Epoch [258/1500], Loss: 0.0084\n",
            "Epoch [259/1500], Step [1/65], Loss: 0.0087\n",
            "Epoch [259/1500], Loss: 0.0087\n",
            "Epoch [260/1500], Step [1/65], Loss: 0.0083\n",
            "Epoch [260/1500], Loss: 0.0088\n",
            "Epoch [261/1500], Step [1/65], Loss: 0.0072\n",
            "Epoch [261/1500], Loss: 0.0088\n",
            "Epoch [262/1500], Step [1/65], Loss: 0.0091\n",
            "Epoch [262/1500], Loss: 0.0086\n",
            "Epoch [263/1500], Step [1/65], Loss: 0.0087\n",
            "Epoch [263/1500], Loss: 0.0085\n",
            "Epoch [264/1500], Step [1/65], Loss: 0.0079\n",
            "Epoch [264/1500], Loss: 0.0083\n",
            "Epoch [265/1500], Step [1/65], Loss: 0.0087\n",
            "Epoch [265/1500], Loss: 0.0083\n",
            "Epoch [266/1500], Step [1/65], Loss: 0.0102\n",
            "Epoch [266/1500], Loss: 0.0082\n",
            "Epoch [267/1500], Step [1/65], Loss: 0.0076\n",
            "Epoch [267/1500], Loss: 0.0083\n",
            "Epoch [268/1500], Step [1/65], Loss: 0.0070\n",
            "Epoch [268/1500], Loss: 0.0085\n",
            "Epoch [269/1500], Step [1/65], Loss: 0.0084\n",
            "Epoch [269/1500], Loss: 0.0084\n",
            "Epoch [270/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [270/1500], Loss: 0.0083\n",
            "Epoch [271/1500], Step [1/65], Loss: 0.0075\n",
            "Epoch [271/1500], Loss: 0.0082\n",
            "Epoch [272/1500], Step [1/65], Loss: 0.0084\n",
            "Epoch [272/1500], Loss: 0.0082\n",
            "Epoch [273/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [273/1500], Loss: 0.0081\n",
            "Epoch [274/1500], Step [1/65], Loss: 0.0080\n",
            "Epoch [274/1500], Loss: 0.0080\n",
            "Epoch [275/1500], Step [1/65], Loss: 0.0084\n",
            "Epoch [275/1500], Loss: 0.0080\n",
            "Epoch [276/1500], Step [1/65], Loss: 0.0084\n",
            "Epoch [276/1500], Loss: 0.0079\n",
            "Epoch [277/1500], Step [1/65], Loss: 0.0074\n",
            "Epoch [277/1500], Loss: 0.0080\n",
            "Epoch [278/1500], Step [1/65], Loss: 0.0070\n",
            "Epoch [278/1500], Loss: 0.0080\n",
            "Epoch [279/1500], Step [1/65], Loss: 0.0078\n",
            "Epoch [279/1500], Loss: 0.0080\n",
            "Epoch [280/1500], Step [1/65], Loss: 0.0066\n",
            "Epoch [280/1500], Loss: 0.0080\n",
            "Epoch [281/1500], Step [1/65], Loss: 0.0089\n",
            "Epoch [281/1500], Loss: 0.0079\n",
            "Epoch [282/1500], Step [1/65], Loss: 0.0075\n",
            "Epoch [282/1500], Loss: 0.0079\n",
            "Epoch [283/1500], Step [1/65], Loss: 0.0075\n",
            "Epoch [283/1500], Loss: 0.0079\n",
            "Epoch [284/1500], Step [1/65], Loss: 0.0076\n",
            "Epoch [284/1500], Loss: 0.0079\n",
            "Epoch [285/1500], Step [1/65], Loss: 0.0072\n",
            "Epoch [285/1500], Loss: 0.0078\n",
            "Epoch [286/1500], Step [1/65], Loss: 0.0079\n",
            "Epoch [286/1500], Loss: 0.0078\n",
            "Epoch [287/1500], Step [1/65], Loss: 0.0090\n",
            "Epoch [287/1500], Loss: 0.0079\n",
            "Epoch [288/1500], Step [1/65], Loss: 0.0089\n",
            "Epoch [288/1500], Loss: 0.0081\n",
            "Epoch [289/1500], Step [1/65], Loss: 0.0084\n",
            "Epoch [289/1500], Loss: 0.0082\n",
            "Epoch [290/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [290/1500], Loss: 0.0081\n",
            "Epoch [291/1500], Step [1/65], Loss: 0.0081\n",
            "Epoch [291/1500], Loss: 0.0081\n",
            "Epoch [292/1500], Step [1/65], Loss: 0.0075\n",
            "Epoch [292/1500], Loss: 0.0079\n",
            "Epoch [293/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [293/1500], Loss: 0.0079\n",
            "Epoch [294/1500], Step [1/65], Loss: 0.0086\n",
            "Epoch [294/1500], Loss: 0.0081\n",
            "Epoch [295/1500], Step [1/65], Loss: 0.0082\n",
            "Epoch [295/1500], Loss: 0.0083\n",
            "Epoch [296/1500], Step [1/65], Loss: 0.0093\n",
            "Epoch [296/1500], Loss: 0.0080\n",
            "Epoch [297/1500], Step [1/65], Loss: 0.0085\n",
            "Epoch [297/1500], Loss: 0.0077\n",
            "Epoch [298/1500], Step [1/65], Loss: 0.0073\n",
            "Epoch [298/1500], Loss: 0.0077\n",
            "Epoch [299/1500], Step [1/65], Loss: 0.0084\n",
            "Epoch [299/1500], Loss: 0.0076\n",
            "Epoch [300/1500], Step [1/65], Loss: 0.0071\n",
            "Epoch [300/1500], Loss: 0.0076\n",
            "Epoch [301/1500], Step [1/65], Loss: 0.0090\n",
            "Epoch [301/1500], Loss: 0.0077\n",
            "Epoch [302/1500], Step [1/65], Loss: 0.0070\n",
            "Epoch [302/1500], Loss: 0.0077\n",
            "Epoch [303/1500], Step [1/65], Loss: 0.0083\n",
            "Epoch [303/1500], Loss: 0.0076\n",
            "Epoch [304/1500], Step [1/65], Loss: 0.0101\n",
            "Epoch [304/1500], Loss: 0.0076\n",
            "Epoch [305/1500], Step [1/65], Loss: 0.0073\n",
            "Epoch [305/1500], Loss: 0.0075\n",
            "Epoch [306/1500], Step [1/65], Loss: 0.0069\n",
            "Epoch [306/1500], Loss: 0.0075\n",
            "Epoch [307/1500], Step [1/65], Loss: 0.0071\n",
            "Epoch [307/1500], Loss: 0.0075\n",
            "Epoch [308/1500], Step [1/65], Loss: 0.0076\n",
            "Epoch [308/1500], Loss: 0.0077\n",
            "Epoch [309/1500], Step [1/65], Loss: 0.0091\n",
            "Epoch [309/1500], Loss: 0.0077\n",
            "Epoch [310/1500], Step [1/65], Loss: 0.0081\n",
            "Epoch [310/1500], Loss: 0.0077\n",
            "Epoch [311/1500], Step [1/65], Loss: 0.0098\n",
            "Epoch [311/1500], Loss: 0.0077\n",
            "Epoch [312/1500], Step [1/65], Loss: 0.0076\n",
            "Epoch [312/1500], Loss: 0.0075\n",
            "Epoch [313/1500], Step [1/65], Loss: 0.0082\n",
            "Epoch [313/1500], Loss: 0.0075\n",
            "Epoch [314/1500], Step [1/65], Loss: 0.0075\n",
            "Epoch [314/1500], Loss: 0.0076\n",
            "Epoch [315/1500], Step [1/65], Loss: 0.0063\n",
            "Epoch [315/1500], Loss: 0.0076\n",
            "Epoch [316/1500], Step [1/65], Loss: 0.0083\n",
            "Epoch [316/1500], Loss: 0.0077\n",
            "Epoch [317/1500], Step [1/65], Loss: 0.0084\n",
            "Epoch [317/1500], Loss: 0.0076\n",
            "Epoch [318/1500], Step [1/65], Loss: 0.0070\n",
            "Epoch [318/1500], Loss: 0.0076\n",
            "Epoch [319/1500], Step [1/65], Loss: 0.0092\n",
            "Epoch [319/1500], Loss: 0.0076\n",
            "Epoch [320/1500], Step [1/65], Loss: 0.0069\n",
            "Epoch [320/1500], Loss: 0.0076\n",
            "Epoch [321/1500], Step [1/65], Loss: 0.0080\n",
            "Epoch [321/1500], Loss: 0.0075\n",
            "Epoch [322/1500], Step [1/65], Loss: 0.0066\n",
            "Epoch [322/1500], Loss: 0.0074\n",
            "Epoch [323/1500], Step [1/65], Loss: 0.0069\n",
            "Epoch [323/1500], Loss: 0.0074\n",
            "Epoch [324/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [324/1500], Loss: 0.0073\n",
            "Epoch [325/1500], Step [1/65], Loss: 0.0072\n",
            "Epoch [325/1500], Loss: 0.0072\n",
            "Epoch [326/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [326/1500], Loss: 0.0072\n",
            "Epoch [327/1500], Step [1/65], Loss: 0.0075\n",
            "Epoch [327/1500], Loss: 0.0072\n",
            "Epoch [328/1500], Step [1/65], Loss: 0.0079\n",
            "Epoch [328/1500], Loss: 0.0073\n",
            "Epoch [329/1500], Step [1/65], Loss: 0.0078\n",
            "Epoch [329/1500], Loss: 0.0074\n",
            "Epoch [330/1500], Step [1/65], Loss: 0.0065\n",
            "Epoch [330/1500], Loss: 0.0075\n",
            "Epoch [331/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [331/1500], Loss: 0.0074\n",
            "Epoch [332/1500], Step [1/65], Loss: 0.0076\n",
            "Epoch [332/1500], Loss: 0.0074\n",
            "Epoch [333/1500], Step [1/65], Loss: 0.0093\n",
            "Epoch [333/1500], Loss: 0.0078\n",
            "Epoch [334/1500], Step [1/65], Loss: 0.0082\n",
            "Epoch [334/1500], Loss: 0.0077\n",
            "Epoch [335/1500], Step [1/65], Loss: 0.0073\n",
            "Epoch [335/1500], Loss: 0.0075\n",
            "Epoch [336/1500], Step [1/65], Loss: 0.0080\n",
            "Epoch [336/1500], Loss: 0.0074\n",
            "Epoch [337/1500], Step [1/65], Loss: 0.0063\n",
            "Epoch [337/1500], Loss: 0.0072\n",
            "Epoch [338/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [338/1500], Loss: 0.0072\n",
            "Epoch [339/1500], Step [1/65], Loss: 0.0085\n",
            "Epoch [339/1500], Loss: 0.0075\n",
            "Epoch [340/1500], Step [1/65], Loss: 0.0077\n",
            "Epoch [340/1500], Loss: 0.0075\n",
            "Epoch [341/1500], Step [1/65], Loss: 0.0083\n",
            "Epoch [341/1500], Loss: 0.0073\n",
            "Epoch [342/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [342/1500], Loss: 0.0072\n",
            "Epoch [343/1500], Step [1/65], Loss: 0.0081\n",
            "Epoch [343/1500], Loss: 0.0070\n",
            "Epoch [344/1500], Step [1/65], Loss: 0.0068\n",
            "Epoch [344/1500], Loss: 0.0070\n",
            "Epoch [345/1500], Step [1/65], Loss: 0.0072\n",
            "Epoch [345/1500], Loss: 0.0070\n",
            "Epoch [346/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [346/1500], Loss: 0.0070\n",
            "Epoch [347/1500], Step [1/65], Loss: 0.0078\n",
            "Epoch [347/1500], Loss: 0.0070\n",
            "Epoch [348/1500], Step [1/65], Loss: 0.0080\n",
            "Epoch [348/1500], Loss: 0.0071\n",
            "Epoch [349/1500], Step [1/65], Loss: 0.0074\n",
            "Epoch [349/1500], Loss: 0.0070\n",
            "Epoch [350/1500], Step [1/65], Loss: 0.0071\n",
            "Epoch [350/1500], Loss: 0.0070\n",
            "Epoch [351/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [351/1500], Loss: 0.0072\n",
            "Epoch [352/1500], Step [1/65], Loss: 0.0078\n",
            "Epoch [352/1500], Loss: 0.0073\n",
            "Epoch [353/1500], Step [1/65], Loss: 0.0062\n",
            "Epoch [353/1500], Loss: 0.0074\n",
            "Epoch [354/1500], Step [1/65], Loss: 0.0072\n",
            "Epoch [354/1500], Loss: 0.0074\n",
            "Epoch [355/1500], Step [1/65], Loss: 0.0080\n",
            "Epoch [355/1500], Loss: 0.0073\n",
            "Epoch [356/1500], Step [1/65], Loss: 0.0089\n",
            "Epoch [356/1500], Loss: 0.0072\n",
            "Epoch [357/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [357/1500], Loss: 0.0072\n",
            "Epoch [358/1500], Step [1/65], Loss: 0.0079\n",
            "Epoch [358/1500], Loss: 0.0070\n",
            "Epoch [359/1500], Step [1/65], Loss: 0.0066\n",
            "Epoch [359/1500], Loss: 0.0070\n",
            "Epoch [360/1500], Step [1/65], Loss: 0.0059\n",
            "Epoch [360/1500], Loss: 0.0070\n",
            "Epoch [361/1500], Step [1/65], Loss: 0.0064\n",
            "Epoch [361/1500], Loss: 0.0070\n",
            "Epoch [362/1500], Step [1/65], Loss: 0.0070\n",
            "Epoch [362/1500], Loss: 0.0071\n",
            "Epoch [363/1500], Step [1/65], Loss: 0.0065\n",
            "Epoch [363/1500], Loss: 0.0069\n",
            "Epoch [364/1500], Step [1/65], Loss: 0.0079\n",
            "Epoch [364/1500], Loss: 0.0071\n",
            "Epoch [365/1500], Step [1/65], Loss: 0.0091\n",
            "Epoch [365/1500], Loss: 0.0071\n",
            "Epoch [366/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [366/1500], Loss: 0.0070\n",
            "Epoch [367/1500], Step [1/65], Loss: 0.0070\n",
            "Epoch [367/1500], Loss: 0.0069\n",
            "Epoch [368/1500], Step [1/65], Loss: 0.0077\n",
            "Epoch [368/1500], Loss: 0.0069\n",
            "Epoch [369/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [369/1500], Loss: 0.0069\n",
            "Epoch [370/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [370/1500], Loss: 0.0069\n",
            "Epoch [371/1500], Step [1/65], Loss: 0.0075\n",
            "Epoch [371/1500], Loss: 0.0069\n",
            "Epoch [372/1500], Step [1/65], Loss: 0.0071\n",
            "Epoch [372/1500], Loss: 0.0070\n",
            "Epoch [373/1500], Step [1/65], Loss: 0.0085\n",
            "Epoch [373/1500], Loss: 0.0069\n",
            "Epoch [374/1500], Step [1/65], Loss: 0.0062\n",
            "Epoch [374/1500], Loss: 0.0069\n",
            "Epoch [375/1500], Step [1/65], Loss: 0.0080\n",
            "Epoch [375/1500], Loss: 0.0069\n",
            "Epoch [376/1500], Step [1/65], Loss: 0.0072\n",
            "Epoch [376/1500], Loss: 0.0068\n",
            "Epoch [377/1500], Step [1/65], Loss: 0.0065\n",
            "Epoch [377/1500], Loss: 0.0069\n",
            "Epoch [378/1500], Step [1/65], Loss: 0.0072\n",
            "Epoch [378/1500], Loss: 0.0068\n",
            "Epoch [379/1500], Step [1/65], Loss: 0.0073\n",
            "Epoch [379/1500], Loss: 0.0068\n",
            "Epoch [380/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [380/1500], Loss: 0.0068\n",
            "Epoch [381/1500], Step [1/65], Loss: 0.0073\n",
            "Epoch [381/1500], Loss: 0.0068\n",
            "Epoch [382/1500], Step [1/65], Loss: 0.0083\n",
            "Epoch [382/1500], Loss: 0.0069\n",
            "Epoch [383/1500], Step [1/65], Loss: 0.0063\n",
            "Epoch [383/1500], Loss: 0.0072\n",
            "Epoch [384/1500], Step [1/65], Loss: 0.0069\n",
            "Epoch [384/1500], Loss: 0.0070\n",
            "Epoch [385/1500], Step [1/65], Loss: 0.0100\n",
            "Epoch [385/1500], Loss: 0.0071\n",
            "Epoch [386/1500], Step [1/65], Loss: 0.0065\n",
            "Epoch [386/1500], Loss: 0.0069\n",
            "Epoch [387/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [387/1500], Loss: 0.0069\n",
            "Epoch [388/1500], Step [1/65], Loss: 0.0068\n",
            "Epoch [388/1500], Loss: 0.0069\n",
            "Epoch [389/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [389/1500], Loss: 0.0068\n",
            "Epoch [390/1500], Step [1/65], Loss: 0.0066\n",
            "Epoch [390/1500], Loss: 0.0068\n",
            "Epoch [391/1500], Step [1/65], Loss: 0.0075\n",
            "Epoch [391/1500], Loss: 0.0068\n",
            "Epoch [392/1500], Step [1/65], Loss: 0.0072\n",
            "Epoch [392/1500], Loss: 0.0068\n",
            "Epoch [393/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [393/1500], Loss: 0.0066\n",
            "Epoch [394/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [394/1500], Loss: 0.0066\n",
            "Epoch [395/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [395/1500], Loss: 0.0066\n",
            "Epoch [396/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [396/1500], Loss: 0.0065\n",
            "Epoch [397/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [397/1500], Loss: 0.0066\n",
            "Epoch [398/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [398/1500], Loss: 0.0066\n",
            "Epoch [399/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [399/1500], Loss: 0.0065\n",
            "Epoch [400/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [400/1500], Loss: 0.0066\n",
            "Epoch [401/1500], Step [1/65], Loss: 0.0068\n",
            "Epoch [401/1500], Loss: 0.0066\n",
            "Epoch [402/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [402/1500], Loss: 0.0067\n",
            "Epoch [403/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [403/1500], Loss: 0.0067\n",
            "Epoch [404/1500], Step [1/65], Loss: 0.0064\n",
            "Epoch [404/1500], Loss: 0.0067\n",
            "Epoch [405/1500], Step [1/65], Loss: 0.0062\n",
            "Epoch [405/1500], Loss: 0.0067\n",
            "Epoch [406/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [406/1500], Loss: 0.0066\n",
            "Epoch [407/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [407/1500], Loss: 0.0065\n",
            "Epoch [408/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [408/1500], Loss: 0.0064\n",
            "Epoch [409/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [409/1500], Loss: 0.0064\n",
            "Epoch [410/1500], Step [1/65], Loss: 0.0079\n",
            "Epoch [410/1500], Loss: 0.0064\n",
            "Epoch [411/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [411/1500], Loss: 0.0064\n",
            "Epoch [412/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [412/1500], Loss: 0.0065\n",
            "Epoch [413/1500], Step [1/65], Loss: 0.0059\n",
            "Epoch [413/1500], Loss: 0.0065\n",
            "Epoch [414/1500], Step [1/65], Loss: 0.0064\n",
            "Epoch [414/1500], Loss: 0.0065\n",
            "Epoch [415/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [415/1500], Loss: 0.0065\n",
            "Epoch [416/1500], Step [1/65], Loss: 0.0070\n",
            "Epoch [416/1500], Loss: 0.0065\n",
            "Epoch [417/1500], Step [1/65], Loss: 0.0071\n",
            "Epoch [417/1500], Loss: 0.0065\n",
            "Epoch [418/1500], Step [1/65], Loss: 0.0081\n",
            "Epoch [418/1500], Loss: 0.0064\n",
            "Epoch [419/1500], Step [1/65], Loss: 0.0072\n",
            "Epoch [419/1500], Loss: 0.0064\n",
            "Epoch [420/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [420/1500], Loss: 0.0064\n",
            "Epoch [421/1500], Step [1/65], Loss: 0.0091\n",
            "Epoch [421/1500], Loss: 0.0064\n",
            "Epoch [422/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [422/1500], Loss: 0.0064\n",
            "Epoch [423/1500], Step [1/65], Loss: 0.0079\n",
            "Epoch [423/1500], Loss: 0.0066\n",
            "Epoch [424/1500], Step [1/65], Loss: 0.0065\n",
            "Epoch [424/1500], Loss: 0.0065\n",
            "Epoch [425/1500], Step [1/65], Loss: 0.0062\n",
            "Epoch [425/1500], Loss: 0.0067\n",
            "Epoch [426/1500], Step [1/65], Loss: 0.0076\n",
            "Epoch [426/1500], Loss: 0.0067\n",
            "Epoch [427/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [427/1500], Loss: 0.0066\n",
            "Epoch [428/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [428/1500], Loss: 0.0067\n",
            "Epoch [429/1500], Step [1/65], Loss: 0.0081\n",
            "Epoch [429/1500], Loss: 0.0065\n",
            "Epoch [430/1500], Step [1/65], Loss: 0.0075\n",
            "Epoch [430/1500], Loss: 0.0064\n",
            "Epoch [431/1500], Step [1/65], Loss: 0.0088\n",
            "Epoch [431/1500], Loss: 0.0064\n",
            "Epoch [432/1500], Step [1/65], Loss: 0.0066\n",
            "Epoch [432/1500], Loss: 0.0063\n",
            "Epoch [433/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [433/1500], Loss: 0.0062\n",
            "Epoch [434/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [434/1500], Loss: 0.0061\n",
            "Epoch [435/1500], Step [1/65], Loss: 0.0064\n",
            "Epoch [435/1500], Loss: 0.0061\n",
            "Epoch [436/1500], Step [1/65], Loss: 0.0079\n",
            "Epoch [436/1500], Loss: 0.0061\n",
            "Epoch [437/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [437/1500], Loss: 0.0060\n",
            "Epoch [438/1500], Step [1/65], Loss: 0.0059\n",
            "Epoch [438/1500], Loss: 0.0061\n",
            "Epoch [439/1500], Step [1/65], Loss: 0.0069\n",
            "Epoch [439/1500], Loss: 0.0062\n",
            "Epoch [440/1500], Step [1/65], Loss: 0.0075\n",
            "Epoch [440/1500], Loss: 0.0062\n",
            "Epoch [441/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [441/1500], Loss: 0.0063\n",
            "Epoch [442/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [442/1500], Loss: 0.0063\n",
            "Epoch [443/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [443/1500], Loss: 0.0063\n",
            "Epoch [444/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [444/1500], Loss: 0.0063\n",
            "Epoch [445/1500], Step [1/65], Loss: 0.0063\n",
            "Epoch [445/1500], Loss: 0.0062\n",
            "Epoch [446/1500], Step [1/65], Loss: 0.0069\n",
            "Epoch [446/1500], Loss: 0.0062\n",
            "Epoch [447/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [447/1500], Loss: 0.0061\n",
            "Epoch [448/1500], Step [1/65], Loss: 0.0070\n",
            "Epoch [448/1500], Loss: 0.0061\n",
            "Epoch [449/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [449/1500], Loss: 0.0062\n",
            "Epoch [450/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [450/1500], Loss: 0.0062\n",
            "Epoch [451/1500], Step [1/65], Loss: 0.0075\n",
            "Epoch [451/1500], Loss: 0.0062\n",
            "Epoch [452/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [452/1500], Loss: 0.0063\n",
            "Epoch [453/1500], Step [1/65], Loss: 0.0065\n",
            "Epoch [453/1500], Loss: 0.0064\n",
            "Epoch [454/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [454/1500], Loss: 0.0064\n",
            "Epoch [455/1500], Step [1/65], Loss: 0.0070\n",
            "Epoch [455/1500], Loss: 0.0064\n",
            "Epoch [456/1500], Step [1/65], Loss: 0.0086\n",
            "Epoch [456/1500], Loss: 0.0063\n",
            "Epoch [457/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [457/1500], Loss: 0.0064\n",
            "Epoch [458/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [458/1500], Loss: 0.0063\n",
            "Epoch [459/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [459/1500], Loss: 0.0061\n",
            "Epoch [460/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [460/1500], Loss: 0.0060\n",
            "Epoch [461/1500], Step [1/65], Loss: 0.0072\n",
            "Epoch [461/1500], Loss: 0.0059\n",
            "Epoch [462/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [462/1500], Loss: 0.0059\n",
            "Epoch [463/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [463/1500], Loss: 0.0058\n",
            "Epoch [464/1500], Step [1/65], Loss: 0.0063\n",
            "Epoch [464/1500], Loss: 0.0058\n",
            "Epoch [465/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [465/1500], Loss: 0.0059\n",
            "Epoch [466/1500], Step [1/65], Loss: 0.0068\n",
            "Epoch [466/1500], Loss: 0.0060\n",
            "Epoch [467/1500], Step [1/65], Loss: 0.0078\n",
            "Epoch [467/1500], Loss: 0.0060\n",
            "Epoch [468/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [468/1500], Loss: 0.0061\n",
            "Epoch [469/1500], Step [1/65], Loss: 0.0076\n",
            "Epoch [469/1500], Loss: 0.0062\n",
            "Epoch [470/1500], Step [1/65], Loss: 0.0063\n",
            "Epoch [470/1500], Loss: 0.0062\n",
            "Epoch [471/1500], Step [1/65], Loss: 0.0062\n",
            "Epoch [471/1500], Loss: 0.0061\n",
            "Epoch [472/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [472/1500], Loss: 0.0060\n",
            "Epoch [473/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [473/1500], Loss: 0.0059\n",
            "Epoch [474/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [474/1500], Loss: 0.0059\n",
            "Epoch [475/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [475/1500], Loss: 0.0059\n",
            "Epoch [476/1500], Step [1/65], Loss: 0.0062\n",
            "Epoch [476/1500], Loss: 0.0061\n",
            "Epoch [477/1500], Step [1/65], Loss: 0.0065\n",
            "Epoch [477/1500], Loss: 0.0060\n",
            "Epoch [478/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [478/1500], Loss: 0.0060\n",
            "Epoch [479/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [479/1500], Loss: 0.0060\n",
            "Epoch [480/1500], Step [1/65], Loss: 0.0059\n",
            "Epoch [480/1500], Loss: 0.0061\n",
            "Epoch [481/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [481/1500], Loss: 0.0060\n",
            "Epoch [482/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [482/1500], Loss: 0.0058\n",
            "Epoch [483/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [483/1500], Loss: 0.0061\n",
            "Epoch [484/1500], Step [1/65], Loss: 0.0063\n",
            "Epoch [484/1500], Loss: 0.0060\n",
            "Epoch [485/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [485/1500], Loss: 0.0058\n",
            "Epoch [486/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [486/1500], Loss: 0.0057\n",
            "Epoch [487/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [487/1500], Loss: 0.0057\n",
            "Epoch [488/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [488/1500], Loss: 0.0058\n",
            "Epoch [489/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [489/1500], Loss: 0.0059\n",
            "Epoch [490/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [490/1500], Loss: 0.0060\n",
            "Epoch [491/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [491/1500], Loss: 0.0060\n",
            "Epoch [492/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [492/1500], Loss: 0.0060\n",
            "Epoch [493/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [493/1500], Loss: 0.0058\n",
            "Epoch [494/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [494/1500], Loss: 0.0057\n",
            "Epoch [495/1500], Step [1/65], Loss: 0.0071\n",
            "Epoch [495/1500], Loss: 0.0056\n",
            "Epoch [496/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [496/1500], Loss: 0.0057\n",
            "Epoch [497/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [497/1500], Loss: 0.0057\n",
            "Epoch [498/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [498/1500], Loss: 0.0057\n",
            "Epoch [499/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [499/1500], Loss: 0.0057\n",
            "Epoch [500/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [500/1500], Loss: 0.0057\n",
            "Epoch [501/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [501/1500], Loss: 0.0056\n",
            "Epoch [502/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [502/1500], Loss: 0.0057\n",
            "Epoch [503/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [503/1500], Loss: 0.0057\n",
            "Epoch [504/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [504/1500], Loss: 0.0057\n",
            "Epoch [505/1500], Step [1/65], Loss: 0.0068\n",
            "Epoch [505/1500], Loss: 0.0057\n",
            "Epoch [506/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [506/1500], Loss: 0.0057\n",
            "Epoch [507/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [507/1500], Loss: 0.0057\n",
            "Epoch [508/1500], Step [1/65], Loss: 0.0065\n",
            "Epoch [508/1500], Loss: 0.0056\n",
            "Epoch [509/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [509/1500], Loss: 0.0057\n",
            "Epoch [510/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [510/1500], Loss: 0.0058\n",
            "Epoch [511/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [511/1500], Loss: 0.0057\n",
            "Epoch [512/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [512/1500], Loss: 0.0057\n",
            "Epoch [513/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [513/1500], Loss: 0.0057\n",
            "Epoch [514/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [514/1500], Loss: 0.0057\n",
            "Epoch [515/1500], Step [1/65], Loss: 0.0065\n",
            "Epoch [515/1500], Loss: 0.0057\n",
            "Epoch [516/1500], Step [1/65], Loss: 0.0076\n",
            "Epoch [516/1500], Loss: 0.0058\n",
            "Epoch [517/1500], Step [1/65], Loss: 0.0066\n",
            "Epoch [517/1500], Loss: 0.0058\n",
            "Epoch [518/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [518/1500], Loss: 0.0058\n",
            "Epoch [519/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [519/1500], Loss: 0.0058\n",
            "Epoch [520/1500], Step [1/65], Loss: 0.0065\n",
            "Epoch [520/1500], Loss: 0.0057\n",
            "Epoch [521/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [521/1500], Loss: 0.0056\n",
            "Epoch [522/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [522/1500], Loss: 0.0055\n",
            "Epoch [523/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [523/1500], Loss: 0.0055\n",
            "Epoch [524/1500], Step [1/65], Loss: 0.0063\n",
            "Epoch [524/1500], Loss: 0.0054\n",
            "Epoch [525/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [525/1500], Loss: 0.0056\n",
            "Epoch [526/1500], Step [1/65], Loss: 0.0062\n",
            "Epoch [526/1500], Loss: 0.0057\n",
            "Epoch [527/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [527/1500], Loss: 0.0056\n",
            "Epoch [528/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [528/1500], Loss: 0.0055\n",
            "Epoch [529/1500], Step [1/65], Loss: 0.0072\n",
            "Epoch [529/1500], Loss: 0.0055\n",
            "Epoch [530/1500], Step [1/65], Loss: 0.0070\n",
            "Epoch [530/1500], Loss: 0.0054\n",
            "Epoch [531/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [531/1500], Loss: 0.0054\n",
            "Epoch [532/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [532/1500], Loss: 0.0053\n",
            "Epoch [533/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [533/1500], Loss: 0.0053\n",
            "Epoch [534/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [534/1500], Loss: 0.0054\n",
            "Epoch [535/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [535/1500], Loss: 0.0056\n",
            "Epoch [536/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [536/1500], Loss: 0.0057\n",
            "Epoch [537/1500], Step [1/65], Loss: 0.0069\n",
            "Epoch [537/1500], Loss: 0.0056\n",
            "Epoch [538/1500], Step [1/65], Loss: 0.0067\n",
            "Epoch [538/1500], Loss: 0.0055\n",
            "Epoch [539/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [539/1500], Loss: 0.0054\n",
            "Epoch [540/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [540/1500], Loss: 0.0053\n",
            "Epoch [541/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [541/1500], Loss: 0.0053\n",
            "Epoch [542/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [542/1500], Loss: 0.0052\n",
            "Epoch [543/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [543/1500], Loss: 0.0052\n",
            "Epoch [544/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [544/1500], Loss: 0.0053\n",
            "Epoch [545/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [545/1500], Loss: 0.0053\n",
            "Epoch [546/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [546/1500], Loss: 0.0054\n",
            "Epoch [547/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [547/1500], Loss: 0.0055\n",
            "Epoch [548/1500], Step [1/65], Loss: 0.0062\n",
            "Epoch [548/1500], Loss: 0.0056\n",
            "Epoch [549/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [549/1500], Loss: 0.0055\n",
            "Epoch [550/1500], Step [1/65], Loss: 0.0059\n",
            "Epoch [550/1500], Loss: 0.0055\n",
            "Epoch [551/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [551/1500], Loss: 0.0054\n",
            "Epoch [552/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [552/1500], Loss: 0.0053\n",
            "Epoch [553/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [553/1500], Loss: 0.0054\n",
            "Epoch [554/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [554/1500], Loss: 0.0054\n",
            "Epoch [555/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [555/1500], Loss: 0.0054\n",
            "Epoch [556/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [556/1500], Loss: 0.0053\n",
            "Epoch [557/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [557/1500], Loss: 0.0053\n",
            "Epoch [558/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [558/1500], Loss: 0.0054\n",
            "Epoch [559/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [559/1500], Loss: 0.0053\n",
            "Epoch [560/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [560/1500], Loss: 0.0053\n",
            "Epoch [561/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [561/1500], Loss: 0.0053\n",
            "Epoch [562/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [562/1500], Loss: 0.0052\n",
            "Epoch [563/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [563/1500], Loss: 0.0052\n",
            "Epoch [564/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [564/1500], Loss: 0.0053\n",
            "Epoch [565/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [565/1500], Loss: 0.0053\n",
            "Epoch [566/1500], Step [1/65], Loss: 0.0072\n",
            "Epoch [566/1500], Loss: 0.0053\n",
            "Epoch [567/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [567/1500], Loss: 0.0054\n",
            "Epoch [568/1500], Step [1/65], Loss: 0.0074\n",
            "Epoch [568/1500], Loss: 0.0054\n",
            "Epoch [569/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [569/1500], Loss: 0.0053\n",
            "Epoch [570/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [570/1500], Loss: 0.0053\n",
            "Epoch [571/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [571/1500], Loss: 0.0053\n",
            "Epoch [572/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [572/1500], Loss: 0.0052\n",
            "Epoch [573/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [573/1500], Loss: 0.0052\n",
            "Epoch [574/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [574/1500], Loss: 0.0052\n",
            "Epoch [575/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [575/1500], Loss: 0.0052\n",
            "Epoch [576/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [576/1500], Loss: 0.0052\n",
            "Epoch [577/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [577/1500], Loss: 0.0053\n",
            "Epoch [578/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [578/1500], Loss: 0.0053\n",
            "Epoch [579/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [579/1500], Loss: 0.0052\n",
            "Epoch [580/1500], Step [1/65], Loss: 0.0069\n",
            "Epoch [580/1500], Loss: 0.0051\n",
            "Epoch [581/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [581/1500], Loss: 0.0051\n",
            "Epoch [582/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [582/1500], Loss: 0.0051\n",
            "Epoch [583/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [583/1500], Loss: 0.0051\n",
            "Epoch [584/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [584/1500], Loss: 0.0051\n",
            "Epoch [585/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [585/1500], Loss: 0.0050\n",
            "Epoch [586/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [586/1500], Loss: 0.0051\n",
            "Epoch [587/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [587/1500], Loss: 0.0051\n",
            "Epoch [588/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [588/1500], Loss: 0.0052\n",
            "Epoch [589/1500], Step [1/65], Loss: 0.0069\n",
            "Epoch [589/1500], Loss: 0.0052\n",
            "Epoch [590/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [590/1500], Loss: 0.0052\n",
            "Epoch [591/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [591/1500], Loss: 0.0052\n",
            "Epoch [592/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [592/1500], Loss: 0.0053\n",
            "Epoch [593/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [593/1500], Loss: 0.0052\n",
            "Epoch [594/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [594/1500], Loss: 0.0052\n",
            "Epoch [595/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [595/1500], Loss: 0.0052\n",
            "Epoch [596/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [596/1500], Loss: 0.0052\n",
            "Epoch [597/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [597/1500], Loss: 0.0051\n",
            "Epoch [598/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [598/1500], Loss: 0.0050\n",
            "Epoch [599/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [599/1500], Loss: 0.0049\n",
            "Epoch [600/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [600/1500], Loss: 0.0049\n",
            "Epoch [601/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [601/1500], Loss: 0.0049\n",
            "Epoch [602/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [602/1500], Loss: 0.0050\n",
            "Epoch [603/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [603/1500], Loss: 0.0051\n",
            "Epoch [604/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [604/1500], Loss: 0.0052\n",
            "Epoch [605/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [605/1500], Loss: 0.0052\n",
            "Epoch [606/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [606/1500], Loss: 0.0052\n",
            "Epoch [607/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [607/1500], Loss: 0.0051\n",
            "Epoch [608/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [608/1500], Loss: 0.0051\n",
            "Epoch [609/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [609/1500], Loss: 0.0051\n",
            "Epoch [610/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [610/1500], Loss: 0.0050\n",
            "Epoch [611/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [611/1500], Loss: 0.0051\n",
            "Epoch [612/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [612/1500], Loss: 0.0051\n",
            "Epoch [613/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [613/1500], Loss: 0.0053\n",
            "Epoch [614/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [614/1500], Loss: 0.0051\n",
            "Epoch [615/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [615/1500], Loss: 0.0051\n",
            "Epoch [616/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [616/1500], Loss: 0.0050\n",
            "Epoch [617/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [617/1500], Loss: 0.0050\n",
            "Epoch [618/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [618/1500], Loss: 0.0050\n",
            "Epoch [619/1500], Step [1/65], Loss: 0.0070\n",
            "Epoch [619/1500], Loss: 0.0050\n",
            "Epoch [620/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [620/1500], Loss: 0.0050\n",
            "Epoch [621/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [621/1500], Loss: 0.0049\n",
            "Epoch [622/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [622/1500], Loss: 0.0048\n",
            "Epoch [623/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [623/1500], Loss: 0.0049\n",
            "Epoch [624/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [624/1500], Loss: 0.0048\n",
            "Epoch [625/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [625/1500], Loss: 0.0049\n",
            "Epoch [626/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [626/1500], Loss: 0.0049\n",
            "Epoch [627/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [627/1500], Loss: 0.0049\n",
            "Epoch [628/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [628/1500], Loss: 0.0050\n",
            "Epoch [629/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [629/1500], Loss: 0.0050\n",
            "Epoch [630/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [630/1500], Loss: 0.0050\n",
            "Epoch [631/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [631/1500], Loss: 0.0051\n",
            "Epoch [632/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [632/1500], Loss: 0.0052\n",
            "Epoch [633/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [633/1500], Loss: 0.0050\n",
            "Epoch [634/1500], Step [1/65], Loss: 0.0062\n",
            "Epoch [634/1500], Loss: 0.0049\n",
            "Epoch [635/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [635/1500], Loss: 0.0048\n",
            "Epoch [636/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [636/1500], Loss: 0.0047\n",
            "Epoch [637/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [637/1500], Loss: 0.0048\n",
            "Epoch [638/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [638/1500], Loss: 0.0048\n",
            "Epoch [639/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [639/1500], Loss: 0.0048\n",
            "Epoch [640/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [640/1500], Loss: 0.0049\n",
            "Epoch [641/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [641/1500], Loss: 0.0048\n",
            "Epoch [642/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [642/1500], Loss: 0.0048\n",
            "Epoch [643/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [643/1500], Loss: 0.0048\n",
            "Epoch [644/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [644/1500], Loss: 0.0049\n",
            "Epoch [645/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [645/1500], Loss: 0.0050\n",
            "Epoch [646/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [646/1500], Loss: 0.0050\n",
            "Epoch [647/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [647/1500], Loss: 0.0049\n",
            "Epoch [648/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [648/1500], Loss: 0.0049\n",
            "Epoch [649/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [649/1500], Loss: 0.0049\n",
            "Epoch [650/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [650/1500], Loss: 0.0048\n",
            "Epoch [651/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [651/1500], Loss: 0.0048\n",
            "Epoch [652/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [652/1500], Loss: 0.0047\n",
            "Epoch [653/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [653/1500], Loss: 0.0048\n",
            "Epoch [654/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [654/1500], Loss: 0.0048\n",
            "Epoch [655/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [655/1500], Loss: 0.0048\n",
            "Epoch [656/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [656/1500], Loss: 0.0048\n",
            "Epoch [657/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [657/1500], Loss: 0.0048\n",
            "Epoch [658/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [658/1500], Loss: 0.0048\n",
            "Epoch [659/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [659/1500], Loss: 0.0050\n",
            "Epoch [660/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [660/1500], Loss: 0.0049\n",
            "Epoch [661/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [661/1500], Loss: 0.0048\n",
            "Epoch [662/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [662/1500], Loss: 0.0049\n",
            "Epoch [663/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [663/1500], Loss: 0.0049\n",
            "Epoch [664/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [664/1500], Loss: 0.0048\n",
            "Epoch [665/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [665/1500], Loss: 0.0048\n",
            "Epoch [666/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [666/1500], Loss: 0.0048\n",
            "Epoch [667/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [667/1500], Loss: 0.0048\n",
            "Epoch [668/1500], Step [1/65], Loss: 0.0062\n",
            "Epoch [668/1500], Loss: 0.0047\n",
            "Epoch [669/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [669/1500], Loss: 0.0047\n",
            "Epoch [670/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [670/1500], Loss: 0.0047\n",
            "Epoch [671/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [671/1500], Loss: 0.0047\n",
            "Epoch [672/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [672/1500], Loss: 0.0047\n",
            "Epoch [673/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [673/1500], Loss: 0.0048\n",
            "Epoch [674/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [674/1500], Loss: 0.0047\n",
            "Epoch [675/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [675/1500], Loss: 0.0047\n",
            "Epoch [676/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [676/1500], Loss: 0.0047\n",
            "Epoch [677/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [677/1500], Loss: 0.0048\n",
            "Epoch [678/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [678/1500], Loss: 0.0048\n",
            "Epoch [679/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [679/1500], Loss: 0.0048\n",
            "Epoch [680/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [680/1500], Loss: 0.0047\n",
            "Epoch [681/1500], Step [1/65], Loss: 0.0060\n",
            "Epoch [681/1500], Loss: 0.0047\n",
            "Epoch [682/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [682/1500], Loss: 0.0047\n",
            "Epoch [683/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [683/1500], Loss: 0.0047\n",
            "Epoch [684/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [684/1500], Loss: 0.0046\n",
            "Epoch [685/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [685/1500], Loss: 0.0046\n",
            "Epoch [686/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [686/1500], Loss: 0.0047\n",
            "Epoch [687/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [687/1500], Loss: 0.0047\n",
            "Epoch [688/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [688/1500], Loss: 0.0046\n",
            "Epoch [689/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [689/1500], Loss: 0.0047\n",
            "Epoch [690/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [690/1500], Loss: 0.0047\n",
            "Epoch [691/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [691/1500], Loss: 0.0048\n",
            "Epoch [692/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [692/1500], Loss: 0.0048\n",
            "Epoch [693/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [693/1500], Loss: 0.0047\n",
            "Epoch [694/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [694/1500], Loss: 0.0047\n",
            "Epoch [695/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [695/1500], Loss: 0.0047\n",
            "Epoch [696/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [696/1500], Loss: 0.0046\n",
            "Epoch [697/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [697/1500], Loss: 0.0046\n",
            "Epoch [698/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [698/1500], Loss: 0.0046\n",
            "Epoch [699/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [699/1500], Loss: 0.0047\n",
            "Epoch [700/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [700/1500], Loss: 0.0047\n",
            "Epoch [701/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [701/1500], Loss: 0.0046\n",
            "Epoch [702/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [702/1500], Loss: 0.0046\n",
            "Epoch [703/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [703/1500], Loss: 0.0047\n",
            "Epoch [704/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [704/1500], Loss: 0.0047\n",
            "Epoch [705/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [705/1500], Loss: 0.0046\n",
            "Epoch [706/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [706/1500], Loss: 0.0046\n",
            "Epoch [707/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [707/1500], Loss: 0.0046\n",
            "Epoch [708/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [708/1500], Loss: 0.0046\n",
            "Epoch [709/1500], Step [1/65], Loss: 0.0059\n",
            "Epoch [709/1500], Loss: 0.0046\n",
            "Epoch [710/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [710/1500], Loss: 0.0047\n",
            "Epoch [711/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [711/1500], Loss: 0.0048\n",
            "Epoch [712/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [712/1500], Loss: 0.0047\n",
            "Epoch [713/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [713/1500], Loss: 0.0047\n",
            "Epoch [714/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [714/1500], Loss: 0.0046\n",
            "Epoch [715/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [715/1500], Loss: 0.0045\n",
            "Epoch [716/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [716/1500], Loss: 0.0045\n",
            "Epoch [717/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [717/1500], Loss: 0.0045\n",
            "Epoch [718/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [718/1500], Loss: 0.0045\n",
            "Epoch [719/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [719/1500], Loss: 0.0046\n",
            "Epoch [720/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [720/1500], Loss: 0.0046\n",
            "Epoch [721/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [721/1500], Loss: 0.0046\n",
            "Epoch [722/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [722/1500], Loss: 0.0046\n",
            "Epoch [723/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [723/1500], Loss: 0.0046\n",
            "Epoch [724/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [724/1500], Loss: 0.0046\n",
            "Epoch [725/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [725/1500], Loss: 0.0046\n",
            "Epoch [726/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [726/1500], Loss: 0.0047\n",
            "Epoch [727/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [727/1500], Loss: 0.0047\n",
            "Epoch [728/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [728/1500], Loss: 0.0047\n",
            "Epoch [729/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [729/1500], Loss: 0.0046\n",
            "Epoch [730/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [730/1500], Loss: 0.0047\n",
            "Epoch [731/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [731/1500], Loss: 0.0046\n",
            "Epoch [732/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [732/1500], Loss: 0.0046\n",
            "Epoch [733/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [733/1500], Loss: 0.0046\n",
            "Epoch [734/1500], Step [1/65], Loss: 0.0063\n",
            "Epoch [734/1500], Loss: 0.0045\n",
            "Epoch [735/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [735/1500], Loss: 0.0044\n",
            "Epoch [736/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [736/1500], Loss: 0.0045\n",
            "Epoch [737/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [737/1500], Loss: 0.0045\n",
            "Epoch [738/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [738/1500], Loss: 0.0044\n",
            "Epoch [739/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [739/1500], Loss: 0.0045\n",
            "Epoch [740/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [740/1500], Loss: 0.0046\n",
            "Epoch [741/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [741/1500], Loss: 0.0045\n",
            "Epoch [742/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [742/1500], Loss: 0.0045\n",
            "Epoch [743/1500], Step [1/65], Loss: 0.0064\n",
            "Epoch [743/1500], Loss: 0.0045\n",
            "Epoch [744/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [744/1500], Loss: 0.0044\n",
            "Epoch [745/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [745/1500], Loss: 0.0045\n",
            "Epoch [746/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [746/1500], Loss: 0.0045\n",
            "Epoch [747/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [747/1500], Loss: 0.0045\n",
            "Epoch [748/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [748/1500], Loss: 0.0044\n",
            "Epoch [749/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [749/1500], Loss: 0.0044\n",
            "Epoch [750/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [750/1500], Loss: 0.0045\n",
            "Epoch [751/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [751/1500], Loss: 0.0046\n",
            "Epoch [752/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [752/1500], Loss: 0.0045\n",
            "Epoch [753/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [753/1500], Loss: 0.0045\n",
            "Epoch [754/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [754/1500], Loss: 0.0045\n",
            "Epoch [755/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [755/1500], Loss: 0.0045\n",
            "Epoch [756/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [756/1500], Loss: 0.0045\n",
            "Epoch [757/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [757/1500], Loss: 0.0045\n",
            "Epoch [758/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [758/1500], Loss: 0.0045\n",
            "Epoch [759/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [759/1500], Loss: 0.0044\n",
            "Epoch [760/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [760/1500], Loss: 0.0044\n",
            "Epoch [761/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [761/1500], Loss: 0.0044\n",
            "Epoch [762/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [762/1500], Loss: 0.0044\n",
            "Epoch [763/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [763/1500], Loss: 0.0044\n",
            "Epoch [764/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [764/1500], Loss: 0.0045\n",
            "Epoch [765/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [765/1500], Loss: 0.0045\n",
            "Epoch [766/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [766/1500], Loss: 0.0045\n",
            "Epoch [767/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [767/1500], Loss: 0.0046\n",
            "Epoch [768/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [768/1500], Loss: 0.0046\n",
            "Epoch [769/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [769/1500], Loss: 0.0046\n",
            "Epoch [770/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [770/1500], Loss: 0.0045\n",
            "Epoch [771/1500], Step [1/65], Loss: 0.0065\n",
            "Epoch [771/1500], Loss: 0.0045\n",
            "Epoch [772/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [772/1500], Loss: 0.0045\n",
            "Epoch [773/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [773/1500], Loss: 0.0044\n",
            "Epoch [774/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [774/1500], Loss: 0.0045\n",
            "Epoch [775/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [775/1500], Loss: 0.0045\n",
            "Epoch [776/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [776/1500], Loss: 0.0046\n",
            "Epoch [777/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [777/1500], Loss: 0.0045\n",
            "Epoch [778/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [778/1500], Loss: 0.0044\n",
            "Epoch [779/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [779/1500], Loss: 0.0044\n",
            "Epoch [780/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [780/1500], Loss: 0.0043\n",
            "Epoch [781/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [781/1500], Loss: 0.0042\n",
            "Epoch [782/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [782/1500], Loss: 0.0043\n",
            "Epoch [783/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [783/1500], Loss: 0.0044\n",
            "Epoch [784/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [784/1500], Loss: 0.0045\n",
            "Epoch [785/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [785/1500], Loss: 0.0045\n",
            "Epoch [786/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [786/1500], Loss: 0.0044\n",
            "Epoch [787/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [787/1500], Loss: 0.0044\n",
            "Epoch [788/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [788/1500], Loss: 0.0043\n",
            "Epoch [789/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [789/1500], Loss: 0.0044\n",
            "Epoch [790/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [790/1500], Loss: 0.0044\n",
            "Epoch [791/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [791/1500], Loss: 0.0043\n",
            "Epoch [792/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [792/1500], Loss: 0.0044\n",
            "Epoch [793/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [793/1500], Loss: 0.0044\n",
            "Epoch [794/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [794/1500], Loss: 0.0043\n",
            "Epoch [795/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [795/1500], Loss: 0.0044\n",
            "Epoch [796/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [796/1500], Loss: 0.0044\n",
            "Epoch [797/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [797/1500], Loss: 0.0044\n",
            "Epoch [798/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [798/1500], Loss: 0.0044\n",
            "Epoch [799/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [799/1500], Loss: 0.0044\n",
            "Epoch [800/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [800/1500], Loss: 0.0046\n",
            "Epoch [801/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [801/1500], Loss: 0.0044\n",
            "Epoch [802/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [802/1500], Loss: 0.0044\n",
            "Epoch [803/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [803/1500], Loss: 0.0044\n",
            "Epoch [804/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [804/1500], Loss: 0.0044\n",
            "Epoch [805/1500], Step [1/65], Loss: 0.0061\n",
            "Epoch [805/1500], Loss: 0.0043\n",
            "Epoch [806/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [806/1500], Loss: 0.0043\n",
            "Epoch [807/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [807/1500], Loss: 0.0043\n",
            "Epoch [808/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [808/1500], Loss: 0.0044\n",
            "Epoch [809/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [809/1500], Loss: 0.0045\n",
            "Epoch [810/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [810/1500], Loss: 0.0044\n",
            "Epoch [811/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [811/1500], Loss: 0.0044\n",
            "Epoch [812/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [812/1500], Loss: 0.0043\n",
            "Epoch [813/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [813/1500], Loss: 0.0043\n",
            "Epoch [814/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [814/1500], Loss: 0.0042\n",
            "Epoch [815/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [815/1500], Loss: 0.0044\n",
            "Epoch [816/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [816/1500], Loss: 0.0044\n",
            "Epoch [817/1500], Step [1/65], Loss: 0.0066\n",
            "Epoch [817/1500], Loss: 0.0043\n",
            "Epoch [818/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [818/1500], Loss: 0.0043\n",
            "Epoch [819/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [819/1500], Loss: 0.0043\n",
            "Epoch [820/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [820/1500], Loss: 0.0043\n",
            "Epoch [821/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [821/1500], Loss: 0.0043\n",
            "Epoch [822/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [822/1500], Loss: 0.0043\n",
            "Epoch [823/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [823/1500], Loss: 0.0044\n",
            "Epoch [824/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [824/1500], Loss: 0.0043\n",
            "Epoch [825/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [825/1500], Loss: 0.0043\n",
            "Epoch [826/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [826/1500], Loss: 0.0043\n",
            "Epoch [827/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [827/1500], Loss: 0.0043\n",
            "Epoch [828/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [828/1500], Loss: 0.0042\n",
            "Epoch [829/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [829/1500], Loss: 0.0043\n",
            "Epoch [830/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [830/1500], Loss: 0.0043\n",
            "Epoch [831/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [831/1500], Loss: 0.0043\n",
            "Epoch [832/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [832/1500], Loss: 0.0043\n",
            "Epoch [833/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [833/1500], Loss: 0.0043\n",
            "Epoch [834/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [834/1500], Loss: 0.0043\n",
            "Epoch [835/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [835/1500], Loss: 0.0042\n",
            "Epoch [836/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [836/1500], Loss: 0.0042\n",
            "Epoch [837/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [837/1500], Loss: 0.0042\n",
            "Epoch [838/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [838/1500], Loss: 0.0042\n",
            "Epoch [839/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [839/1500], Loss: 0.0042\n",
            "Epoch [840/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [840/1500], Loss: 0.0043\n",
            "Epoch [841/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [841/1500], Loss: 0.0043\n",
            "Epoch [842/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [842/1500], Loss: 0.0044\n",
            "Epoch [843/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [843/1500], Loss: 0.0043\n",
            "Epoch [844/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [844/1500], Loss: 0.0043\n",
            "Epoch [845/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [845/1500], Loss: 0.0043\n",
            "Epoch [846/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [846/1500], Loss: 0.0043\n",
            "Epoch [847/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [847/1500], Loss: 0.0043\n",
            "Epoch [848/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [848/1500], Loss: 0.0044\n",
            "Epoch [849/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [849/1500], Loss: 0.0043\n",
            "Epoch [850/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [850/1500], Loss: 0.0043\n",
            "Epoch [851/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [851/1500], Loss: 0.0042\n",
            "Epoch [852/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [852/1500], Loss: 0.0043\n",
            "Epoch [853/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [853/1500], Loss: 0.0043\n",
            "Epoch [854/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [854/1500], Loss: 0.0043\n",
            "Epoch [855/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [855/1500], Loss: 0.0042\n",
            "Epoch [856/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [856/1500], Loss: 0.0043\n",
            "Epoch [857/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [857/1500], Loss: 0.0042\n",
            "Epoch [858/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [858/1500], Loss: 0.0042\n",
            "Epoch [859/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [859/1500], Loss: 0.0043\n",
            "Epoch [860/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [860/1500], Loss: 0.0043\n",
            "Epoch [861/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [861/1500], Loss: 0.0042\n",
            "Epoch [862/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [862/1500], Loss: 0.0041\n",
            "Epoch [863/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [863/1500], Loss: 0.0041\n",
            "Epoch [864/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [864/1500], Loss: 0.0041\n",
            "Epoch [865/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [865/1500], Loss: 0.0041\n",
            "Epoch [866/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [866/1500], Loss: 0.0041\n",
            "Epoch [867/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [867/1500], Loss: 0.0041\n",
            "Epoch [868/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [868/1500], Loss: 0.0041\n",
            "Epoch [869/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [869/1500], Loss: 0.0042\n",
            "Epoch [870/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [870/1500], Loss: 0.0042\n",
            "Epoch [871/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [871/1500], Loss: 0.0042\n",
            "Epoch [872/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [872/1500], Loss: 0.0042\n",
            "Epoch [873/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [873/1500], Loss: 0.0044\n",
            "Epoch [874/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [874/1500], Loss: 0.0046\n",
            "Epoch [875/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [875/1500], Loss: 0.0045\n",
            "Epoch [876/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [876/1500], Loss: 0.0044\n",
            "Epoch [877/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [877/1500], Loss: 0.0043\n",
            "Epoch [878/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [878/1500], Loss: 0.0043\n",
            "Epoch [879/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [879/1500], Loss: 0.0042\n",
            "Epoch [880/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [880/1500], Loss: 0.0042\n",
            "Epoch [881/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [881/1500], Loss: 0.0041\n",
            "Epoch [882/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [882/1500], Loss: 0.0041\n",
            "Epoch [883/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [883/1500], Loss: 0.0040\n",
            "Epoch [884/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [884/1500], Loss: 0.0040\n",
            "Epoch [885/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [885/1500], Loss: 0.0040\n",
            "Epoch [886/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [886/1500], Loss: 0.0040\n",
            "Epoch [887/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [887/1500], Loss: 0.0040\n",
            "Epoch [888/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [888/1500], Loss: 0.0040\n",
            "Epoch [889/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [889/1500], Loss: 0.0041\n",
            "Epoch [890/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [890/1500], Loss: 0.0042\n",
            "Epoch [891/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [891/1500], Loss: 0.0043\n",
            "Epoch [892/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [892/1500], Loss: 0.0045\n",
            "Epoch [893/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [893/1500], Loss: 0.0047\n",
            "Epoch [894/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [894/1500], Loss: 0.0046\n",
            "Epoch [895/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [895/1500], Loss: 0.0044\n",
            "Epoch [896/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [896/1500], Loss: 0.0043\n",
            "Epoch [897/1500], Step [1/65], Loss: 0.0058\n",
            "Epoch [897/1500], Loss: 0.0041\n",
            "Epoch [898/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [898/1500], Loss: 0.0040\n",
            "Epoch [899/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [899/1500], Loss: 0.0040\n",
            "Epoch [900/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [900/1500], Loss: 0.0041\n",
            "Epoch [901/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [901/1500], Loss: 0.0041\n",
            "Epoch [902/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [902/1500], Loss: 0.0040\n",
            "Epoch [903/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [903/1500], Loss: 0.0042\n",
            "Epoch [904/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [904/1500], Loss: 0.0042\n",
            "Epoch [905/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [905/1500], Loss: 0.0041\n",
            "Epoch [906/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [906/1500], Loss: 0.0041\n",
            "Epoch [907/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [907/1500], Loss: 0.0040\n",
            "Epoch [908/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [908/1500], Loss: 0.0040\n",
            "Epoch [909/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [909/1500], Loss: 0.0040\n",
            "Epoch [910/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [910/1500], Loss: 0.0041\n",
            "Epoch [911/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [911/1500], Loss: 0.0041\n",
            "Epoch [912/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [912/1500], Loss: 0.0042\n",
            "Epoch [913/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [913/1500], Loss: 0.0043\n",
            "Epoch [914/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [914/1500], Loss: 0.0042\n",
            "Epoch [915/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [915/1500], Loss: 0.0042\n",
            "Epoch [916/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [916/1500], Loss: 0.0041\n",
            "Epoch [917/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [917/1500], Loss: 0.0040\n",
            "Epoch [918/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [918/1500], Loss: 0.0040\n",
            "Epoch [919/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [919/1500], Loss: 0.0040\n",
            "Epoch [920/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [920/1500], Loss: 0.0040\n",
            "Epoch [921/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [921/1500], Loss: 0.0040\n",
            "Epoch [922/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [922/1500], Loss: 0.0040\n",
            "Epoch [923/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [923/1500], Loss: 0.0041\n",
            "Epoch [924/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [924/1500], Loss: 0.0041\n",
            "Epoch [925/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [925/1500], Loss: 0.0041\n",
            "Epoch [926/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [926/1500], Loss: 0.0041\n",
            "Epoch [927/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [927/1500], Loss: 0.0042\n",
            "Epoch [928/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [928/1500], Loss: 0.0043\n",
            "Epoch [929/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [929/1500], Loss: 0.0043\n",
            "Epoch [930/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [930/1500], Loss: 0.0044\n",
            "Epoch [931/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [931/1500], Loss: 0.0043\n",
            "Epoch [932/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [932/1500], Loss: 0.0041\n",
            "Epoch [933/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [933/1500], Loss: 0.0042\n",
            "Epoch [934/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [934/1500], Loss: 0.0042\n",
            "Epoch [935/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [935/1500], Loss: 0.0041\n",
            "Epoch [936/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [936/1500], Loss: 0.0040\n",
            "Epoch [937/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [937/1500], Loss: 0.0040\n",
            "Epoch [938/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [938/1500], Loss: 0.0039\n",
            "Epoch [939/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [939/1500], Loss: 0.0039\n",
            "Epoch [940/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [940/1500], Loss: 0.0039\n",
            "Epoch [941/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [941/1500], Loss: 0.0039\n",
            "Epoch [942/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [942/1500], Loss: 0.0039\n",
            "Epoch [943/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [943/1500], Loss: 0.0039\n",
            "Epoch [944/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [944/1500], Loss: 0.0039\n",
            "Epoch [945/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [945/1500], Loss: 0.0040\n",
            "Epoch [946/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [946/1500], Loss: 0.0040\n",
            "Epoch [947/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [947/1500], Loss: 0.0040\n",
            "Epoch [948/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [948/1500], Loss: 0.0041\n",
            "Epoch [949/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [949/1500], Loss: 0.0040\n",
            "Epoch [950/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [950/1500], Loss: 0.0040\n",
            "Epoch [951/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [951/1500], Loss: 0.0040\n",
            "Epoch [952/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [952/1500], Loss: 0.0040\n",
            "Epoch [953/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [953/1500], Loss: 0.0040\n",
            "Epoch [954/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [954/1500], Loss: 0.0041\n",
            "Epoch [955/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [955/1500], Loss: 0.0041\n",
            "Epoch [956/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [956/1500], Loss: 0.0041\n",
            "Epoch [957/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [957/1500], Loss: 0.0041\n",
            "Epoch [958/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [958/1500], Loss: 0.0042\n",
            "Epoch [959/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [959/1500], Loss: 0.0041\n",
            "Epoch [960/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [960/1500], Loss: 0.0041\n",
            "Epoch [961/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [961/1500], Loss: 0.0040\n",
            "Epoch [962/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [962/1500], Loss: 0.0040\n",
            "Epoch [963/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [963/1500], Loss: 0.0040\n",
            "Epoch [964/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [964/1500], Loss: 0.0040\n",
            "Epoch [965/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [965/1500], Loss: 0.0040\n",
            "Epoch [966/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [966/1500], Loss: 0.0040\n",
            "Epoch [967/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [967/1500], Loss: 0.0040\n",
            "Epoch [968/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [968/1500], Loss: 0.0040\n",
            "Epoch [969/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [969/1500], Loss: 0.0040\n",
            "Epoch [970/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [970/1500], Loss: 0.0040\n",
            "Epoch [971/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [971/1500], Loss: 0.0040\n",
            "Epoch [972/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [972/1500], Loss: 0.0040\n",
            "Epoch [973/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [973/1500], Loss: 0.0041\n",
            "Epoch [974/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [974/1500], Loss: 0.0041\n",
            "Epoch [975/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [975/1500], Loss: 0.0040\n",
            "Epoch [976/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [976/1500], Loss: 0.0040\n",
            "Epoch [977/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [977/1500], Loss: 0.0041\n",
            "Epoch [978/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [978/1500], Loss: 0.0040\n",
            "Epoch [979/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [979/1500], Loss: 0.0041\n",
            "Epoch [980/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [980/1500], Loss: 0.0041\n",
            "Epoch [981/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [981/1500], Loss: 0.0040\n",
            "Epoch [982/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [982/1500], Loss: 0.0040\n",
            "Epoch [983/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [983/1500], Loss: 0.0040\n",
            "Epoch [984/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [984/1500], Loss: 0.0040\n",
            "Epoch [985/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [985/1500], Loss: 0.0040\n",
            "Epoch [986/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [986/1500], Loss: 0.0040\n",
            "Epoch [987/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [987/1500], Loss: 0.0040\n",
            "Epoch [988/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [988/1500], Loss: 0.0039\n",
            "Epoch [989/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [989/1500], Loss: 0.0039\n",
            "Epoch [990/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [990/1500], Loss: 0.0039\n",
            "Epoch [991/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [991/1500], Loss: 0.0039\n",
            "Epoch [992/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [992/1500], Loss: 0.0038\n",
            "Epoch [993/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [993/1500], Loss: 0.0039\n",
            "Epoch [994/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [994/1500], Loss: 0.0039\n",
            "Epoch [995/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [995/1500], Loss: 0.0039\n",
            "Epoch [996/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [996/1500], Loss: 0.0040\n",
            "Epoch [997/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [997/1500], Loss: 0.0041\n",
            "Epoch [998/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [998/1500], Loss: 0.0041\n",
            "Epoch [999/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [999/1500], Loss: 0.0040\n",
            "Epoch [1000/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1000/1500], Loss: 0.0039\n",
            "Epoch [1001/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [1001/1500], Loss: 0.0039\n",
            "Epoch [1002/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1002/1500], Loss: 0.0039\n",
            "Epoch [1003/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1003/1500], Loss: 0.0039\n",
            "Epoch [1004/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [1004/1500], Loss: 0.0039\n",
            "Epoch [1005/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1005/1500], Loss: 0.0039\n",
            "Epoch [1006/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1006/1500], Loss: 0.0040\n",
            "Epoch [1007/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [1007/1500], Loss: 0.0041\n",
            "Epoch [1008/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1008/1500], Loss: 0.0041\n",
            "Epoch [1009/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1009/1500], Loss: 0.0040\n",
            "Epoch [1010/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1010/1500], Loss: 0.0040\n",
            "Epoch [1011/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1011/1500], Loss: 0.0040\n",
            "Epoch [1012/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1012/1500], Loss: 0.0039\n",
            "Epoch [1013/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1013/1500], Loss: 0.0039\n",
            "Epoch [1014/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1014/1500], Loss: 0.0039\n",
            "Epoch [1015/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1015/1500], Loss: 0.0039\n",
            "Epoch [1016/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [1016/1500], Loss: 0.0039\n",
            "Epoch [1017/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [1017/1500], Loss: 0.0039\n",
            "Epoch [1018/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1018/1500], Loss: 0.0039\n",
            "Epoch [1019/1500], Step [1/65], Loss: 0.0062\n",
            "Epoch [1019/1500], Loss: 0.0039\n",
            "Epoch [1020/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1020/1500], Loss: 0.0039\n",
            "Epoch [1021/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1021/1500], Loss: 0.0039\n",
            "Epoch [1022/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1022/1500], Loss: 0.0038\n",
            "Epoch [1023/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [1023/1500], Loss: 0.0038\n",
            "Epoch [1024/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1024/1500], Loss: 0.0039\n",
            "Epoch [1025/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [1025/1500], Loss: 0.0039\n",
            "Epoch [1026/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1026/1500], Loss: 0.0039\n",
            "Epoch [1027/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1027/1500], Loss: 0.0039\n",
            "Epoch [1028/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1028/1500], Loss: 0.0039\n",
            "Epoch [1029/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1029/1500], Loss: 0.0039\n",
            "Epoch [1030/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1030/1500], Loss: 0.0038\n",
            "Epoch [1031/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1031/1500], Loss: 0.0038\n",
            "Epoch [1032/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1032/1500], Loss: 0.0038\n",
            "Epoch [1033/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1033/1500], Loss: 0.0039\n",
            "Epoch [1034/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1034/1500], Loss: 0.0039\n",
            "Epoch [1035/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1035/1500], Loss: 0.0040\n",
            "Epoch [1036/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1036/1500], Loss: 0.0041\n",
            "Epoch [1037/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1037/1500], Loss: 0.0041\n",
            "Epoch [1038/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1038/1500], Loss: 0.0040\n",
            "Epoch [1039/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [1039/1500], Loss: 0.0039\n",
            "Epoch [1040/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1040/1500], Loss: 0.0039\n",
            "Epoch [1041/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1041/1500], Loss: 0.0039\n",
            "Epoch [1042/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [1042/1500], Loss: 0.0039\n",
            "Epoch [1043/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1043/1500], Loss: 0.0038\n",
            "Epoch [1044/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1044/1500], Loss: 0.0038\n",
            "Epoch [1045/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1045/1500], Loss: 0.0038\n",
            "Epoch [1046/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1046/1500], Loss: 0.0038\n",
            "Epoch [1047/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1047/1500], Loss: 0.0038\n",
            "Epoch [1048/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1048/1500], Loss: 0.0038\n",
            "Epoch [1049/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1049/1500], Loss: 0.0038\n",
            "Epoch [1050/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1050/1500], Loss: 0.0039\n",
            "Epoch [1051/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1051/1500], Loss: 0.0039\n",
            "Epoch [1052/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1052/1500], Loss: 0.0039\n",
            "Epoch [1053/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1053/1500], Loss: 0.0039\n",
            "Epoch [1054/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1054/1500], Loss: 0.0039\n",
            "Epoch [1055/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1055/1500], Loss: 0.0040\n",
            "Epoch [1056/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1056/1500], Loss: 0.0039\n",
            "Epoch [1057/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1057/1500], Loss: 0.0039\n",
            "Epoch [1058/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1058/1500], Loss: 0.0040\n",
            "Epoch [1059/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1059/1500], Loss: 0.0041\n",
            "Epoch [1060/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [1060/1500], Loss: 0.0041\n",
            "Epoch [1061/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1061/1500], Loss: 0.0039\n",
            "Epoch [1062/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [1062/1500], Loss: 0.0038\n",
            "Epoch [1063/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1063/1500], Loss: 0.0037\n",
            "Epoch [1064/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1064/1500], Loss: 0.0037\n",
            "Epoch [1065/1500], Step [1/65], Loss: 0.0056\n",
            "Epoch [1065/1500], Loss: 0.0037\n",
            "Epoch [1066/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1066/1500], Loss: 0.0037\n",
            "Epoch [1067/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1067/1500], Loss: 0.0037\n",
            "Epoch [1068/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1068/1500], Loss: 0.0037\n",
            "Epoch [1069/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1069/1500], Loss: 0.0037\n",
            "Epoch [1070/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1070/1500], Loss: 0.0037\n",
            "Epoch [1071/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [1071/1500], Loss: 0.0037\n",
            "Epoch [1072/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1072/1500], Loss: 0.0038\n",
            "Epoch [1073/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1073/1500], Loss: 0.0038\n",
            "Epoch [1074/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1074/1500], Loss: 0.0038\n",
            "Epoch [1075/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1075/1500], Loss: 0.0039\n",
            "Epoch [1076/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1076/1500], Loss: 0.0040\n",
            "Epoch [1077/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [1077/1500], Loss: 0.0040\n",
            "Epoch [1078/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1078/1500], Loss: 0.0041\n",
            "Epoch [1079/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1079/1500], Loss: 0.0041\n",
            "Epoch [1080/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1080/1500], Loss: 0.0039\n",
            "Epoch [1081/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1081/1500], Loss: 0.0039\n",
            "Epoch [1082/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1082/1500], Loss: 0.0038\n",
            "Epoch [1083/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1083/1500], Loss: 0.0038\n",
            "Epoch [1084/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1084/1500], Loss: 0.0038\n",
            "Epoch [1085/1500], Step [1/65], Loss: 0.0062\n",
            "Epoch [1085/1500], Loss: 0.0037\n",
            "Epoch [1086/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1086/1500], Loss: 0.0037\n",
            "Epoch [1087/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1087/1500], Loss: 0.0038\n",
            "Epoch [1088/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1088/1500], Loss: 0.0038\n",
            "Epoch [1089/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [1089/1500], Loss: 0.0038\n",
            "Epoch [1090/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1090/1500], Loss: 0.0038\n",
            "Epoch [1091/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [1091/1500], Loss: 0.0038\n",
            "Epoch [1092/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1092/1500], Loss: 0.0037\n",
            "Epoch [1093/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1093/1500], Loss: 0.0038\n",
            "Epoch [1094/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1094/1500], Loss: 0.0038\n",
            "Epoch [1095/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1095/1500], Loss: 0.0038\n",
            "Epoch [1096/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1096/1500], Loss: 0.0037\n",
            "Epoch [1097/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1097/1500], Loss: 0.0038\n",
            "Epoch [1098/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1098/1500], Loss: 0.0038\n",
            "Epoch [1099/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1099/1500], Loss: 0.0039\n",
            "Epoch [1100/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1100/1500], Loss: 0.0039\n",
            "Epoch [1101/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1101/1500], Loss: 0.0040\n",
            "Epoch [1102/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [1102/1500], Loss: 0.0039\n",
            "Epoch [1103/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1103/1500], Loss: 0.0038\n",
            "Epoch [1104/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1104/1500], Loss: 0.0038\n",
            "Epoch [1105/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1105/1500], Loss: 0.0038\n",
            "Epoch [1106/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1106/1500], Loss: 0.0038\n",
            "Epoch [1107/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1107/1500], Loss: 0.0037\n",
            "Epoch [1108/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [1108/1500], Loss: 0.0036\n",
            "Epoch [1109/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1109/1500], Loss: 0.0037\n",
            "Epoch [1110/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [1110/1500], Loss: 0.0037\n",
            "Epoch [1111/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [1111/1500], Loss: 0.0037\n",
            "Epoch [1112/1500], Step [1/65], Loss: 0.0057\n",
            "Epoch [1112/1500], Loss: 0.0038\n",
            "Epoch [1113/1500], Step [1/65], Loss: 0.0024\n",
            "Epoch [1113/1500], Loss: 0.0037\n",
            "Epoch [1114/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1114/1500], Loss: 0.0037\n",
            "Epoch [1115/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1115/1500], Loss: 0.0037\n",
            "Epoch [1116/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1116/1500], Loss: 0.0037\n",
            "Epoch [1117/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1117/1500], Loss: 0.0037\n",
            "Epoch [1118/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1118/1500], Loss: 0.0037\n",
            "Epoch [1119/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1119/1500], Loss: 0.0037\n",
            "Epoch [1120/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1120/1500], Loss: 0.0037\n",
            "Epoch [1121/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1121/1500], Loss: 0.0036\n",
            "Epoch [1122/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1122/1500], Loss: 0.0038\n",
            "Epoch [1123/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [1123/1500], Loss: 0.0038\n",
            "Epoch [1124/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1124/1500], Loss: 0.0038\n",
            "Epoch [1125/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1125/1500], Loss: 0.0038\n",
            "Epoch [1126/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1126/1500], Loss: 0.0038\n",
            "Epoch [1127/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1127/1500], Loss: 0.0039\n",
            "Epoch [1128/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1128/1500], Loss: 0.0038\n",
            "Epoch [1129/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1129/1500], Loss: 0.0038\n",
            "Epoch [1130/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1130/1500], Loss: 0.0037\n",
            "Epoch [1131/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1131/1500], Loss: 0.0037\n",
            "Epoch [1132/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1132/1500], Loss: 0.0037\n",
            "Epoch [1133/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1133/1500], Loss: 0.0037\n",
            "Epoch [1134/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1134/1500], Loss: 0.0037\n",
            "Epoch [1135/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1135/1500], Loss: 0.0037\n",
            "Epoch [1136/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1136/1500], Loss: 0.0036\n",
            "Epoch [1137/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1137/1500], Loss: 0.0036\n",
            "Epoch [1138/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1138/1500], Loss: 0.0036\n",
            "Epoch [1139/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [1139/1500], Loss: 0.0037\n",
            "Epoch [1140/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1140/1500], Loss: 0.0037\n",
            "Epoch [1141/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1141/1500], Loss: 0.0037\n",
            "Epoch [1142/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [1142/1500], Loss: 0.0037\n",
            "Epoch [1143/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1143/1500], Loss: 0.0037\n",
            "Epoch [1144/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1144/1500], Loss: 0.0037\n",
            "Epoch [1145/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [1145/1500], Loss: 0.0037\n",
            "Epoch [1146/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1146/1500], Loss: 0.0038\n",
            "Epoch [1147/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1147/1500], Loss: 0.0038\n",
            "Epoch [1148/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [1148/1500], Loss: 0.0038\n",
            "Epoch [1149/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [1149/1500], Loss: 0.0038\n",
            "Epoch [1150/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1150/1500], Loss: 0.0038\n",
            "Epoch [1151/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1151/1500], Loss: 0.0037\n",
            "Epoch [1152/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1152/1500], Loss: 0.0037\n",
            "Epoch [1153/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1153/1500], Loss: 0.0037\n",
            "Epoch [1154/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1154/1500], Loss: 0.0037\n",
            "Epoch [1155/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1155/1500], Loss: 0.0037\n",
            "Epoch [1156/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [1156/1500], Loss: 0.0037\n",
            "Epoch [1157/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1157/1500], Loss: 0.0038\n",
            "Epoch [1158/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [1158/1500], Loss: 0.0037\n",
            "Epoch [1159/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [1159/1500], Loss: 0.0037\n",
            "Epoch [1160/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1160/1500], Loss: 0.0037\n",
            "Epoch [1161/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1161/1500], Loss: 0.0036\n",
            "Epoch [1162/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1162/1500], Loss: 0.0036\n",
            "Epoch [1163/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1163/1500], Loss: 0.0037\n",
            "Epoch [1164/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1164/1500], Loss: 0.0037\n",
            "Epoch [1165/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1165/1500], Loss: 0.0037\n",
            "Epoch [1166/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1166/1500], Loss: 0.0037\n",
            "Epoch [1167/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1167/1500], Loss: 0.0036\n",
            "Epoch [1168/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1168/1500], Loss: 0.0036\n",
            "Epoch [1169/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1169/1500], Loss: 0.0036\n",
            "Epoch [1170/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1170/1500], Loss: 0.0036\n",
            "Epoch [1171/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1171/1500], Loss: 0.0036\n",
            "Epoch [1172/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1172/1500], Loss: 0.0036\n",
            "Epoch [1173/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1173/1500], Loss: 0.0036\n",
            "Epoch [1174/1500], Step [1/65], Loss: 0.0055\n",
            "Epoch [1174/1500], Loss: 0.0036\n",
            "Epoch [1175/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1175/1500], Loss: 0.0036\n",
            "Epoch [1176/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1176/1500], Loss: 0.0036\n",
            "Epoch [1177/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [1177/1500], Loss: 0.0036\n",
            "Epoch [1178/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1178/1500], Loss: 0.0036\n",
            "Epoch [1179/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1179/1500], Loss: 0.0036\n",
            "Epoch [1180/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1180/1500], Loss: 0.0037\n",
            "Epoch [1181/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1181/1500], Loss: 0.0037\n",
            "Epoch [1182/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1182/1500], Loss: 0.0036\n",
            "Epoch [1183/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1183/1500], Loss: 0.0036\n",
            "Epoch [1184/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1184/1500], Loss: 0.0036\n",
            "Epoch [1185/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1185/1500], Loss: 0.0037\n",
            "Epoch [1186/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1186/1500], Loss: 0.0037\n",
            "Epoch [1187/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1187/1500], Loss: 0.0037\n",
            "Epoch [1188/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1188/1500], Loss: 0.0037\n",
            "Epoch [1189/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1189/1500], Loss: 0.0037\n",
            "Epoch [1190/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [1190/1500], Loss: 0.0037\n",
            "Epoch [1191/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1191/1500], Loss: 0.0037\n",
            "Epoch [1192/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [1192/1500], Loss: 0.0037\n",
            "Epoch [1193/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [1193/1500], Loss: 0.0037\n",
            "Epoch [1194/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1194/1500], Loss: 0.0036\n",
            "Epoch [1195/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1195/1500], Loss: 0.0036\n",
            "Epoch [1196/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1196/1500], Loss: 0.0036\n",
            "Epoch [1197/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1197/1500], Loss: 0.0036\n",
            "Epoch [1198/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1198/1500], Loss: 0.0035\n",
            "Epoch [1199/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1199/1500], Loss: 0.0035\n",
            "Epoch [1200/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1200/1500], Loss: 0.0036\n",
            "Epoch [1201/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1201/1500], Loss: 0.0036\n",
            "Epoch [1202/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1202/1500], Loss: 0.0036\n",
            "Epoch [1203/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1203/1500], Loss: 0.0037\n",
            "Epoch [1204/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1204/1500], Loss: 0.0036\n",
            "Epoch [1205/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1205/1500], Loss: 0.0036\n",
            "Epoch [1206/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1206/1500], Loss: 0.0036\n",
            "Epoch [1207/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1207/1500], Loss: 0.0036\n",
            "Epoch [1208/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1208/1500], Loss: 0.0036\n",
            "Epoch [1209/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1209/1500], Loss: 0.0037\n",
            "Epoch [1210/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1210/1500], Loss: 0.0036\n",
            "Epoch [1211/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1211/1500], Loss: 0.0035\n",
            "Epoch [1212/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1212/1500], Loss: 0.0036\n",
            "Epoch [1213/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1213/1500], Loss: 0.0036\n",
            "Epoch [1214/1500], Step [1/65], Loss: 0.0059\n",
            "Epoch [1214/1500], Loss: 0.0036\n",
            "Epoch [1215/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1215/1500], Loss: 0.0035\n",
            "Epoch [1216/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1216/1500], Loss: 0.0036\n",
            "Epoch [1217/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1217/1500], Loss: 0.0036\n",
            "Epoch [1218/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1218/1500], Loss: 0.0036\n",
            "Epoch [1219/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [1219/1500], Loss: 0.0036\n",
            "Epoch [1220/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1220/1500], Loss: 0.0036\n",
            "Epoch [1221/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1221/1500], Loss: 0.0037\n",
            "Epoch [1222/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1222/1500], Loss: 0.0039\n",
            "Epoch [1223/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1223/1500], Loss: 0.0038\n",
            "Epoch [1224/1500], Step [1/65], Loss: 0.0054\n",
            "Epoch [1224/1500], Loss: 0.0037\n",
            "Epoch [1225/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1225/1500], Loss: 0.0036\n",
            "Epoch [1226/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1226/1500], Loss: 0.0035\n",
            "Epoch [1227/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [1227/1500], Loss: 0.0035\n",
            "Epoch [1228/1500], Step [1/65], Loss: 0.0025\n",
            "Epoch [1228/1500], Loss: 0.0036\n",
            "Epoch [1229/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1229/1500], Loss: 0.0036\n",
            "Epoch [1230/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1230/1500], Loss: 0.0036\n",
            "Epoch [1231/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1231/1500], Loss: 0.0035\n",
            "Epoch [1232/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1232/1500], Loss: 0.0035\n",
            "Epoch [1233/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1233/1500], Loss: 0.0035\n",
            "Epoch [1234/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1234/1500], Loss: 0.0035\n",
            "Epoch [1235/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1235/1500], Loss: 0.0035\n",
            "Epoch [1236/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1236/1500], Loss: 0.0035\n",
            "Epoch [1237/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1237/1500], Loss: 0.0035\n",
            "Epoch [1238/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1238/1500], Loss: 0.0035\n",
            "Epoch [1239/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [1239/1500], Loss: 0.0036\n",
            "Epoch [1240/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1240/1500], Loss: 0.0036\n",
            "Epoch [1241/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [1241/1500], Loss: 0.0036\n",
            "Epoch [1242/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1242/1500], Loss: 0.0036\n",
            "Epoch [1243/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1243/1500], Loss: 0.0036\n",
            "Epoch [1244/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1244/1500], Loss: 0.0037\n",
            "Epoch [1245/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1245/1500], Loss: 0.0037\n",
            "Epoch [1246/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1246/1500], Loss: 0.0037\n",
            "Epoch [1247/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1247/1500], Loss: 0.0037\n",
            "Epoch [1248/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [1248/1500], Loss: 0.0037\n",
            "Epoch [1249/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1249/1500], Loss: 0.0037\n",
            "Epoch [1250/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1250/1500], Loss: 0.0036\n",
            "Epoch [1251/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1251/1500], Loss: 0.0035\n",
            "Epoch [1252/1500], Step [1/65], Loss: 0.0024\n",
            "Epoch [1252/1500], Loss: 0.0035\n",
            "Epoch [1253/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1253/1500], Loss: 0.0034\n",
            "Epoch [1254/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [1254/1500], Loss: 0.0034\n",
            "Epoch [1255/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1255/1500], Loss: 0.0035\n",
            "Epoch [1256/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [1256/1500], Loss: 0.0034\n",
            "Epoch [1257/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1257/1500], Loss: 0.0035\n",
            "Epoch [1258/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1258/1500], Loss: 0.0034\n",
            "Epoch [1259/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1259/1500], Loss: 0.0035\n",
            "Epoch [1260/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1260/1500], Loss: 0.0036\n",
            "Epoch [1261/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1261/1500], Loss: 0.0036\n",
            "Epoch [1262/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1262/1500], Loss: 0.0036\n",
            "Epoch [1263/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [1263/1500], Loss: 0.0035\n",
            "Epoch [1264/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1264/1500], Loss: 0.0036\n",
            "Epoch [1265/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [1265/1500], Loss: 0.0036\n",
            "Epoch [1266/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1266/1500], Loss: 0.0036\n",
            "Epoch [1267/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1267/1500], Loss: 0.0036\n",
            "Epoch [1268/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1268/1500], Loss: 0.0035\n",
            "Epoch [1269/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [1269/1500], Loss: 0.0035\n",
            "Epoch [1270/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1270/1500], Loss: 0.0035\n",
            "Epoch [1271/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1271/1500], Loss: 0.0036\n",
            "Epoch [1272/1500], Step [1/65], Loss: 0.0059\n",
            "Epoch [1272/1500], Loss: 0.0036\n",
            "Epoch [1273/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1273/1500], Loss: 0.0037\n",
            "Epoch [1274/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [1274/1500], Loss: 0.0037\n",
            "Epoch [1275/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1275/1500], Loss: 0.0036\n",
            "Epoch [1276/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1276/1500], Loss: 0.0035\n",
            "Epoch [1277/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1277/1500], Loss: 0.0035\n",
            "Epoch [1278/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1278/1500], Loss: 0.0034\n",
            "Epoch [1279/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1279/1500], Loss: 0.0034\n",
            "Epoch [1280/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [1280/1500], Loss: 0.0034\n",
            "Epoch [1281/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1281/1500], Loss: 0.0034\n",
            "Epoch [1282/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1282/1500], Loss: 0.0034\n",
            "Epoch [1283/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1283/1500], Loss: 0.0034\n",
            "Epoch [1284/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1284/1500], Loss: 0.0034\n",
            "Epoch [1285/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1285/1500], Loss: 0.0035\n",
            "Epoch [1286/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1286/1500], Loss: 0.0035\n",
            "Epoch [1287/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1287/1500], Loss: 0.0035\n",
            "Epoch [1288/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1288/1500], Loss: 0.0036\n",
            "Epoch [1289/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1289/1500], Loss: 0.0035\n",
            "Epoch [1290/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1290/1500], Loss: 0.0035\n",
            "Epoch [1291/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1291/1500], Loss: 0.0035\n",
            "Epoch [1292/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1292/1500], Loss: 0.0035\n",
            "Epoch [1293/1500], Step [1/65], Loss: 0.0049\n",
            "Epoch [1293/1500], Loss: 0.0035\n",
            "Epoch [1294/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1294/1500], Loss: 0.0035\n",
            "Epoch [1295/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1295/1500], Loss: 0.0035\n",
            "Epoch [1296/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1296/1500], Loss: 0.0035\n",
            "Epoch [1297/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1297/1500], Loss: 0.0035\n",
            "Epoch [1298/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1298/1500], Loss: 0.0036\n",
            "Epoch [1299/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1299/1500], Loss: 0.0037\n",
            "Epoch [1300/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1300/1500], Loss: 0.0037\n",
            "Epoch [1301/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1301/1500], Loss: 0.0036\n",
            "Epoch [1302/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1302/1500], Loss: 0.0035\n",
            "Epoch [1303/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1303/1500], Loss: 0.0034\n",
            "Epoch [1304/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1304/1500], Loss: 0.0034\n",
            "Epoch [1305/1500], Step [1/65], Loss: 0.0052\n",
            "Epoch [1305/1500], Loss: 0.0034\n",
            "Epoch [1306/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1306/1500], Loss: 0.0034\n",
            "Epoch [1307/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1307/1500], Loss: 0.0034\n",
            "Epoch [1308/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1308/1500], Loss: 0.0034\n",
            "Epoch [1309/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1309/1500], Loss: 0.0034\n",
            "Epoch [1310/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1310/1500], Loss: 0.0035\n",
            "Epoch [1311/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1311/1500], Loss: 0.0035\n",
            "Epoch [1312/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1312/1500], Loss: 0.0035\n",
            "Epoch [1313/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1313/1500], Loss: 0.0035\n",
            "Epoch [1314/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1314/1500], Loss: 0.0034\n",
            "Epoch [1315/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1315/1500], Loss: 0.0035\n",
            "Epoch [1316/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1316/1500], Loss: 0.0035\n",
            "Epoch [1317/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1317/1500], Loss: 0.0034\n",
            "Epoch [1318/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1318/1500], Loss: 0.0035\n",
            "Epoch [1319/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1319/1500], Loss: 0.0035\n",
            "Epoch [1320/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1320/1500], Loss: 0.0035\n",
            "Epoch [1321/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1321/1500], Loss: 0.0034\n",
            "Epoch [1322/1500], Step [1/65], Loss: 0.0021\n",
            "Epoch [1322/1500], Loss: 0.0034\n",
            "Epoch [1323/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1323/1500], Loss: 0.0034\n",
            "Epoch [1324/1500], Step [1/65], Loss: 0.0023\n",
            "Epoch [1324/1500], Loss: 0.0034\n",
            "Epoch [1325/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1325/1500], Loss: 0.0034\n",
            "Epoch [1326/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1326/1500], Loss: 0.0034\n",
            "Epoch [1327/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1327/1500], Loss: 0.0034\n",
            "Epoch [1328/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1328/1500], Loss: 0.0034\n",
            "Epoch [1329/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1329/1500], Loss: 0.0034\n",
            "Epoch [1330/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1330/1500], Loss: 0.0034\n",
            "Epoch [1331/1500], Step [1/65], Loss: 0.0053\n",
            "Epoch [1331/1500], Loss: 0.0034\n",
            "Epoch [1332/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1332/1500], Loss: 0.0035\n",
            "Epoch [1333/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1333/1500], Loss: 0.0035\n",
            "Epoch [1334/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1334/1500], Loss: 0.0034\n",
            "Epoch [1335/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1335/1500], Loss: 0.0035\n",
            "Epoch [1336/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1336/1500], Loss: 0.0035\n",
            "Epoch [1337/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1337/1500], Loss: 0.0035\n",
            "Epoch [1338/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1338/1500], Loss: 0.0034\n",
            "Epoch [1339/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1339/1500], Loss: 0.0034\n",
            "Epoch [1340/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [1340/1500], Loss: 0.0035\n",
            "Epoch [1341/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [1341/1500], Loss: 0.0035\n",
            "Epoch [1342/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1342/1500], Loss: 0.0035\n",
            "Epoch [1343/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1343/1500], Loss: 0.0034\n",
            "Epoch [1344/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1344/1500], Loss: 0.0034\n",
            "Epoch [1345/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1345/1500], Loss: 0.0033\n",
            "Epoch [1346/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1346/1500], Loss: 0.0033\n",
            "Epoch [1347/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1347/1500], Loss: 0.0033\n",
            "Epoch [1348/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1348/1500], Loss: 0.0034\n",
            "Epoch [1349/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1349/1500], Loss: 0.0035\n",
            "Epoch [1350/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1350/1500], Loss: 0.0036\n",
            "Epoch [1351/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1351/1500], Loss: 0.0035\n",
            "Epoch [1352/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1352/1500], Loss: 0.0035\n",
            "Epoch [1353/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1353/1500], Loss: 0.0034\n",
            "Epoch [1354/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1354/1500], Loss: 0.0034\n",
            "Epoch [1355/1500], Step [1/65], Loss: 0.0040\n",
            "Epoch [1355/1500], Loss: 0.0034\n",
            "Epoch [1356/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1356/1500], Loss: 0.0035\n",
            "Epoch [1357/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1357/1500], Loss: 0.0034\n",
            "Epoch [1358/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1358/1500], Loss: 0.0034\n",
            "Epoch [1359/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1359/1500], Loss: 0.0033\n",
            "Epoch [1360/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1360/1500], Loss: 0.0034\n",
            "Epoch [1361/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1361/1500], Loss: 0.0035\n",
            "Epoch [1362/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1362/1500], Loss: 0.0034\n",
            "Epoch [1363/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1363/1500], Loss: 0.0034\n",
            "Epoch [1364/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1364/1500], Loss: 0.0033\n",
            "Epoch [1365/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1365/1500], Loss: 0.0033\n",
            "Epoch [1366/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1366/1500], Loss: 0.0033\n",
            "Epoch [1367/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1367/1500], Loss: 0.0034\n",
            "Epoch [1368/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1368/1500], Loss: 0.0034\n",
            "Epoch [1369/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1369/1500], Loss: 0.0034\n",
            "Epoch [1370/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1370/1500], Loss: 0.0034\n",
            "Epoch [1371/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1371/1500], Loss: 0.0034\n",
            "Epoch [1372/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [1372/1500], Loss: 0.0034\n",
            "Epoch [1373/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1373/1500], Loss: 0.0035\n",
            "Epoch [1374/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1374/1500], Loss: 0.0035\n",
            "Epoch [1375/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1375/1500], Loss: 0.0035\n",
            "Epoch [1376/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1376/1500], Loss: 0.0035\n",
            "Epoch [1377/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1377/1500], Loss: 0.0034\n",
            "Epoch [1378/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1378/1500], Loss: 0.0034\n",
            "Epoch [1379/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1379/1500], Loss: 0.0035\n",
            "Epoch [1380/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1380/1500], Loss: 0.0034\n",
            "Epoch [1381/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1381/1500], Loss: 0.0034\n",
            "Epoch [1382/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1382/1500], Loss: 0.0033\n",
            "Epoch [1383/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1383/1500], Loss: 0.0033\n",
            "Epoch [1384/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1384/1500], Loss: 0.0033\n",
            "Epoch [1385/1500], Step [1/65], Loss: 0.0029\n",
            "Epoch [1385/1500], Loss: 0.0033\n",
            "Epoch [1386/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [1386/1500], Loss: 0.0033\n",
            "Epoch [1387/1500], Step [1/65], Loss: 0.0045\n",
            "Epoch [1387/1500], Loss: 0.0033\n",
            "Epoch [1388/1500], Step [1/65], Loss: 0.0022\n",
            "Epoch [1388/1500], Loss: 0.0034\n",
            "Epoch [1389/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1389/1500], Loss: 0.0033\n",
            "Epoch [1390/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1390/1500], Loss: 0.0034\n",
            "Epoch [1391/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1391/1500], Loss: 0.0034\n",
            "Epoch [1392/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1392/1500], Loss: 0.0033\n",
            "Epoch [1393/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1393/1500], Loss: 0.0034\n",
            "Epoch [1394/1500], Step [1/65], Loss: 0.0023\n",
            "Epoch [1394/1500], Loss: 0.0034\n",
            "Epoch [1395/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1395/1500], Loss: 0.0034\n",
            "Epoch [1396/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1396/1500], Loss: 0.0034\n",
            "Epoch [1397/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1397/1500], Loss: 0.0033\n",
            "Epoch [1398/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1398/1500], Loss: 0.0034\n",
            "Epoch [1399/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1399/1500], Loss: 0.0035\n",
            "Epoch [1400/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1400/1500], Loss: 0.0034\n",
            "Epoch [1401/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1401/1500], Loss: 0.0035\n",
            "Epoch [1402/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1402/1500], Loss: 0.0034\n",
            "Epoch [1403/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1403/1500], Loss: 0.0033\n",
            "Epoch [1404/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1404/1500], Loss: 0.0033\n",
            "Epoch [1405/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1405/1500], Loss: 0.0033\n",
            "Epoch [1406/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1406/1500], Loss: 0.0032\n",
            "Epoch [1407/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1407/1500], Loss: 0.0033\n",
            "Epoch [1408/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1408/1500], Loss: 0.0033\n",
            "Epoch [1409/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1409/1500], Loss: 0.0033\n",
            "Epoch [1410/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1410/1500], Loss: 0.0033\n",
            "Epoch [1411/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1411/1500], Loss: 0.0033\n",
            "Epoch [1412/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1412/1500], Loss: 0.0033\n",
            "Epoch [1413/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1413/1500], Loss: 0.0034\n",
            "Epoch [1414/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1414/1500], Loss: 0.0034\n",
            "Epoch [1415/1500], Step [1/65], Loss: 0.0050\n",
            "Epoch [1415/1500], Loss: 0.0034\n",
            "Epoch [1416/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1416/1500], Loss: 0.0034\n",
            "Epoch [1417/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1417/1500], Loss: 0.0034\n",
            "Epoch [1418/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1418/1500], Loss: 0.0033\n",
            "Epoch [1419/1500], Step [1/65], Loss: 0.0046\n",
            "Epoch [1419/1500], Loss: 0.0034\n",
            "Epoch [1420/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1420/1500], Loss: 0.0033\n",
            "Epoch [1421/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1421/1500], Loss: 0.0033\n",
            "Epoch [1422/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1422/1500], Loss: 0.0033\n",
            "Epoch [1423/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1423/1500], Loss: 0.0033\n",
            "Epoch [1424/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1424/1500], Loss: 0.0033\n",
            "Epoch [1425/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1425/1500], Loss: 0.0033\n",
            "Epoch [1426/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1426/1500], Loss: 0.0033\n",
            "Epoch [1427/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [1427/1500], Loss: 0.0033\n",
            "Epoch [1428/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1428/1500], Loss: 0.0033\n",
            "Epoch [1429/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1429/1500], Loss: 0.0033\n",
            "Epoch [1430/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1430/1500], Loss: 0.0033\n",
            "Epoch [1431/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1431/1500], Loss: 0.0033\n",
            "Epoch [1432/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1432/1500], Loss: 0.0033\n",
            "Epoch [1433/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [1433/1500], Loss: 0.0034\n",
            "Epoch [1434/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1434/1500], Loss: 0.0034\n",
            "Epoch [1435/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1435/1500], Loss: 0.0034\n",
            "Epoch [1436/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1436/1500], Loss: 0.0034\n",
            "Epoch [1437/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1437/1500], Loss: 0.0033\n",
            "Epoch [1438/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1438/1500], Loss: 0.0033\n",
            "Epoch [1439/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1439/1500], Loss: 0.0033\n",
            "Epoch [1440/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1440/1500], Loss: 0.0033\n",
            "Epoch [1441/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1441/1500], Loss: 0.0033\n",
            "Epoch [1442/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1442/1500], Loss: 0.0033\n",
            "Epoch [1443/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1443/1500], Loss: 0.0033\n",
            "Epoch [1444/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1444/1500], Loss: 0.0034\n",
            "Epoch [1445/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1445/1500], Loss: 0.0034\n",
            "Epoch [1446/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1446/1500], Loss: 0.0034\n",
            "Epoch [1447/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1447/1500], Loss: 0.0034\n",
            "Epoch [1448/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1448/1500], Loss: 0.0033\n",
            "Epoch [1449/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1449/1500], Loss: 0.0033\n",
            "Epoch [1450/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1450/1500], Loss: 0.0033\n",
            "Epoch [1451/1500], Step [1/65], Loss: 0.0025\n",
            "Epoch [1451/1500], Loss: 0.0032\n",
            "Epoch [1452/1500], Step [1/65], Loss: 0.0023\n",
            "Epoch [1452/1500], Loss: 0.0032\n",
            "Epoch [1453/1500], Step [1/65], Loss: 0.0047\n",
            "Epoch [1453/1500], Loss: 0.0032\n",
            "Epoch [1454/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1454/1500], Loss: 0.0033\n",
            "Epoch [1455/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1455/1500], Loss: 0.0033\n",
            "Epoch [1456/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1456/1500], Loss: 0.0033\n",
            "Epoch [1457/1500], Step [1/65], Loss: 0.0025\n",
            "Epoch [1457/1500], Loss: 0.0032\n",
            "Epoch [1458/1500], Step [1/65], Loss: 0.0042\n",
            "Epoch [1458/1500], Loss: 0.0033\n",
            "Epoch [1459/1500], Step [1/65], Loss: 0.0039\n",
            "Epoch [1459/1500], Loss: 0.0034\n",
            "Epoch [1460/1500], Step [1/65], Loss: 0.0024\n",
            "Epoch [1460/1500], Loss: 0.0033\n",
            "Epoch [1461/1500], Step [1/65], Loss: 0.0024\n",
            "Epoch [1461/1500], Loss: 0.0033\n",
            "Epoch [1462/1500], Step [1/65], Loss: 0.0024\n",
            "Epoch [1462/1500], Loss: 0.0032\n",
            "Epoch [1463/1500], Step [1/65], Loss: 0.0034\n",
            "Epoch [1463/1500], Loss: 0.0032\n",
            "Epoch [1464/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1464/1500], Loss: 0.0032\n",
            "Epoch [1465/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1465/1500], Loss: 0.0032\n",
            "Epoch [1466/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1466/1500], Loss: 0.0032\n",
            "Epoch [1467/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1467/1500], Loss: 0.0032\n",
            "Epoch [1468/1500], Step [1/65], Loss: 0.0036\n",
            "Epoch [1468/1500], Loss: 0.0032\n",
            "Epoch [1469/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1469/1500], Loss: 0.0032\n",
            "Epoch [1470/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1470/1500], Loss: 0.0032\n",
            "Epoch [1471/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1471/1500], Loss: 0.0033\n",
            "Epoch [1472/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1472/1500], Loss: 0.0033\n",
            "Epoch [1473/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1473/1500], Loss: 0.0033\n",
            "Epoch [1474/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1474/1500], Loss: 0.0034\n",
            "Epoch [1475/1500], Step [1/65], Loss: 0.0048\n",
            "Epoch [1475/1500], Loss: 0.0034\n",
            "Epoch [1476/1500], Step [1/65], Loss: 0.0044\n",
            "Epoch [1476/1500], Loss: 0.0034\n",
            "Epoch [1477/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1477/1500], Loss: 0.0033\n",
            "Epoch [1478/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1478/1500], Loss: 0.0032\n",
            "Epoch [1479/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1479/1500], Loss: 0.0032\n",
            "Epoch [1480/1500], Step [1/65], Loss: 0.0043\n",
            "Epoch [1480/1500], Loss: 0.0033\n",
            "Epoch [1481/1500], Step [1/65], Loss: 0.0051\n",
            "Epoch [1481/1500], Loss: 0.0033\n",
            "Epoch [1482/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1482/1500], Loss: 0.0033\n",
            "Epoch [1483/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1483/1500], Loss: 0.0033\n",
            "Epoch [1484/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1484/1500], Loss: 0.0033\n",
            "Epoch [1485/1500], Step [1/65], Loss: 0.0041\n",
            "Epoch [1485/1500], Loss: 0.0033\n",
            "Epoch [1486/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1486/1500], Loss: 0.0033\n",
            "Epoch [1487/1500], Step [1/65], Loss: 0.0030\n",
            "Epoch [1487/1500], Loss: 0.0033\n",
            "Epoch [1488/1500], Step [1/65], Loss: 0.0026\n",
            "Epoch [1488/1500], Loss: 0.0033\n",
            "Epoch [1489/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1489/1500], Loss: 0.0034\n",
            "Epoch [1490/1500], Step [1/65], Loss: 0.0035\n",
            "Epoch [1490/1500], Loss: 0.0033\n",
            "Epoch [1491/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1491/1500], Loss: 0.0033\n",
            "Epoch [1492/1500], Step [1/65], Loss: 0.0031\n",
            "Epoch [1492/1500], Loss: 0.0033\n",
            "Epoch [1493/1500], Step [1/65], Loss: 0.0033\n",
            "Epoch [1493/1500], Loss: 0.0032\n",
            "Epoch [1494/1500], Step [1/65], Loss: 0.0037\n",
            "Epoch [1494/1500], Loss: 0.0032\n",
            "Epoch [1495/1500], Step [1/65], Loss: 0.0024\n",
            "Epoch [1495/1500], Loss: 0.0032\n",
            "Epoch [1496/1500], Step [1/65], Loss: 0.0028\n",
            "Epoch [1496/1500], Loss: 0.0032\n",
            "Epoch [1497/1500], Step [1/65], Loss: 0.0023\n",
            "Epoch [1497/1500], Loss: 0.0032\n",
            "Epoch [1498/1500], Step [1/65], Loss: 0.0038\n",
            "Epoch [1498/1500], Loss: 0.0032\n",
            "Epoch [1499/1500], Step [1/65], Loss: 0.0027\n",
            "Epoch [1499/1500], Loss: 0.0032\n",
            "Epoch [1500/1500], Step [1/65], Loss: 0.0032\n",
            "Epoch [1500/1500], Loss: 0.0032\n",
            "Model saved as text_to_image_model.pth\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import clip\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "\n",
        "\n",
        "class TextToImageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TextToImageModel, self).__init__()\n",
        "        self.clip_model, _ = clip.load(\"ViT-B/32\", device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.fc = nn.Linear(512, 256 * 16 * 16)  \n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  \n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),   \n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),    \n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1),     \n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, caption_indices):\n",
        "        with torch.no_grad():\n",
        "            text_features = self.clip_model.encode_text(caption_indices).float()  \n",
        "        \n",
        "        image = self.fc(text_features)\n",
        "        image = image.view(-1, 256, 16, 16)  \n",
        "        image = self.conv_layers(image)\n",
        "        return image\n",
        "    \n",
        "    def generate_image(self, text, save_path='generated_image.png'):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            tokens = clip.tokenize([text]).to(next(self.parameters()).device)\n",
        "            image = self.forward(tokens)[0]\n",
        "            save_image(image, save_path)\n",
        "            print(f'Image saved to {save_path}')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TextToImageModel().to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "num_epochs = 1500\n",
        "epoch_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (images, captions) in enumerate(dataloader):\n",
        "        images, captions = images.to(device), captions.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(captions)\n",
        "        \n",
        "        outputs = outputs[:, :, :256, :256]\n",
        "        \n",
        "        loss = criterion(outputs, images)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}')\n",
        "    \n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
        "\n",
        "torch.save(model.state_dict(), 'text_to_image_model.pth')\n",
        "print('Model saved as text_to_image_model.pth')\n",
        "\n",
        "plt.plot(range(1, num_epochs + 1), epoch_losses, label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.savefig('training_loss.png')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image saved to generated_image.png\n"
          ]
        }
      ],
      "source": [
        "def load_model(path):\n",
        "    model = TextToImageModel().to(device)\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "loaded_model = load_model('text_to_image_model.pth')\n",
        "loaded_model.generate_image(\"Young person looking happy\", save_path='generated_image.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18e4ca3ccb8c4317ac6f3ff193a3603d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31a6dc1ae7be4ac2af6bc7bc224fbdbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_726777d84ec645b1a989bd338a1bb302",
            "placeholder": "​",
            "style": "IPY_MODEL_ae6e73f5cdea492ab9edcea3df6e30cd",
            "value": " 2/7 [00:09&lt;00:24,  4.87s/it]"
          }
        },
        "4abacfda6a2b46b8b46696afdd4c798e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e3313fb295f4826ab85b38a1938677d",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7100288dac2a4331a1eb6b2df7b5e18c",
            "value": 2
          }
        },
        "6d0ffa139ad0471481bbe407b089f58c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18e4ca3ccb8c4317ac6f3ff193a3603d",
            "placeholder": "​",
            "style": "IPY_MODEL_8217fbef432b430baf141f99bceaf796",
            "value": "Loading pipeline components...:  29%"
          }
        },
        "7100288dac2a4331a1eb6b2df7b5e18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "726777d84ec645b1a989bd338a1bb302": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8217fbef432b430baf141f99bceaf796": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "913091cf7a604272a81286bfbe2cb3f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d0ffa139ad0471481bbe407b089f58c",
              "IPY_MODEL_4abacfda6a2b46b8b46696afdd4c798e",
              "IPY_MODEL_31a6dc1ae7be4ac2af6bc7bc224fbdbd"
            ],
            "layout": "IPY_MODEL_9af45f0a99374e91b44421571fbf3a36"
          }
        },
        "9af45f0a99374e91b44421571fbf3a36": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e3313fb295f4826ab85b38a1938677d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae6e73f5cdea492ab9edcea3df6e30cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
